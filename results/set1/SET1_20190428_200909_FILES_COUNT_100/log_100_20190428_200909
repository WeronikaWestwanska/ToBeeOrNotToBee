----------------------------------
- Parameters.py                  -
----------------------------------
data_params = {
    "width"                 : 640,
    "height"                : 480,
    "labelled_train_db"     : 'data/labels.train.db',
    "labelled_train_dir"    : 'data/labelled.train/',
    "labelled_validate_db"  : 'data/labels.validate.db',
    "labelled_validate_dir" : 'data/labelled.validate/',
    "segmented_dir"         : 'data/segmented/'
}

model_params = {
    "num_classes" : 2,
    "batch_size"  : 300,
    "epochs"      : 20
}

hyper_params = {
    "max_training_images_count"    : 100,     # if value is -1 then take all training images
    "max_testing_images_count"     : -1,      # if value is -1 then take all training images
    "l2_regularisation"            : 0.0005,
    "dropout"                      : 0.50,
    "learning_rate"                : 0.0001,
    "percentage_train"             : 80,
    "windows_per_image_on_average" : 60,
    "window_size"                  : 40,
    "bee_radius"                   : 20,
    "min_bee_prob"                 : 0.80,
    "max_bee_prob"                 : 1.00,
    "min_bee_prct_window"          : 45.0,
    "bee_window_percentage"        : 20,
    "filters_count"                : 32,
    "kernel_size"                  : 3,
    "padding_to_remove"            : 4,
    "sliding_window_step"          : 2
}
----------------------------------
- Training                       -
----------------------------------
Data Parameters:
Key: width, Value: 640
Key: height, Value: 480
Key: labelled_train_db, Value: data/labels.train.db
Key: labelled_train_dir, Value: data/labelled.train/
Key: labelled_validate_db, Value: data/labels.validate.db
Key: labelled_validate_dir, Value: data/labelled.validate/
Key: segmented_dir, Value: data/segmented/
Model Parameters:
Key: num_classes, Value: 2
Key: batch_size, Value: 300
Key: epochs, Value: 20
Hyper Parameters:
Key: max_training_images_count, Value: 100
Key: max_testing_images_count, Value: -1
Key: l2_regularisation, Value: 0.0005
Key: dropout, Value: 0.5
Key: learning_rate, Value: 0.0001
Key: percentage_train, Value: 80
Key: windows_per_image_on_average, Value: 60
Key: window_size, Value: 40
Key: bee_radius, Value: 20
Key: min_bee_prob, Value: 0.8
Key: max_bee_prob, Value: 1.0
Key: min_bee_prct_window, Value: 45.0
Key: bee_window_percentage, Value: 20
Key: filters_count, Value: 32
Key: kernel_size, Value: 3
Key: padding_to_remove, Value: 4
Key: sliding_window_step, Value: 2
Index is 2
Index is 95
Index is 85
Index is 54
Index is 13
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 40, 40, 3)    0                                            
__________________________________________________________________________________________________
conv1_1 (Conv2D)                (None, 40, 40, 32)   896         input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 40, 40, 32)   9248        conv1_1[0][0]                    
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 20, 20, 32)   0           conv2d_1[0][0]                   
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 20, 20, 64)   18496       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 20, 20, 64)   36928       conv2d_2[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 10, 10, 64)   0           conv2d_3[0][0]                   
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 10, 10, 128)  73856       max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 10, 10, 128)  147584      conv2d_4[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 128)    0           conv2d_5[0][0]                   
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 5, 5, 256)    295168      max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 5, 5, 256)    590080      conv2d_6[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)  (None, 2, 2, 256)    0           conv2d_7[0][0]                   
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 2, 2, 512)    1180160     max_pooling2d_4[0][0]            
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 2, 2, 512)    2359808     conv2d_8[0][0]                   
__________________________________________________________________________________________________
up_sampling2d_1 (UpSampling2D)  (None, 4, 4, 512)    0           conv2d_9[0][0]                   
__________________________________________________________________________________________________
cropping2d_1 (Cropping2D)       (None, 4, 4, 256)    0           conv2d_7[0][0]                   
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 4, 4, 768)    0           up_sampling2d_1[0][0]            
                                                                 cropping2d_1[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 4, 4, 256)    1769728     concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 4, 4, 256)    590080      conv2d_10[0][0]                  
__________________________________________________________________________________________________
up_sampling2d_2 (UpSampling2D)  (None, 8, 8, 256)    0           conv2d_11[0][0]                  
__________________________________________________________________________________________________
cropping2d_2 (Cropping2D)       (None, 8, 8, 128)    0           conv2d_5[0][0]                   
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 8, 8, 384)    0           up_sampling2d_2[0][0]            
                                                                 cropping2d_2[0][0]               
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 8, 8, 128)    442496      concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 8, 8, 128)    147584      conv2d_12[0][0]                  
__________________________________________________________________________________________________
up_sampling2d_3 (UpSampling2D)  (None, 16, 16, 128)  0           conv2d_13[0][0]                  
__________________________________________________________________________________________________
cropping2d_3 (Cropping2D)       (None, 16, 16, 64)   0           conv2d_3[0][0]                   
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 16, 16, 192)  0           up_sampling2d_3[0][0]            
                                                                 cropping2d_3[0][0]               
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 16, 16, 64)   110656      concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 16, 16, 64)   36928       conv2d_14[0][0]                  
__________________________________________________________________________________________________
up_sampling2d_4 (UpSampling2D)  (None, 32, 32, 64)   0           conv2d_15[0][0]                  
__________________________________________________________________________________________________
cropping2d_4 (Cropping2D)       (None, 32, 32, 32)   0           conv2d_1[0][0]                   
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 32, 32, 96)   0           up_sampling2d_4[0][0]            2019-04-28 20:09:28.324921: I T:\src\github\tensorflow\tensorflow\core\platform\cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2019-04-28 20:09:28.626994: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1405] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.8095
pciBusID: 0000:65:00.0
totalMemory: 8.00GiB freeMemory: 6.59GiB
2019-04-28 20:09:28.628291: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1484] Adding visible gpu devices: 0
2019-04-28 20:09:29.429038: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-04-28 20:09:29.429825: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:971]      0 
2019-04-28 20:09:29.430341: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:984] 0:   N 
2019-04-28 20:09:29.430988: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6360 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:65:00.0, compute capability: 6.1)

                                                                 cropping2d_4[0][0]               
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 32, 32, 32)   27680       concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 32, 32, 32)   9248        conv2d_16[0][0]                  
__________________________________________________________________________________________________
zero_padding2d_1 (ZeroPadding2D (None, 40, 40, 32)   0           conv2d_17[0][0]                  
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 40, 40, 2)    66          zero_padding2d_1[0][0]           
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 40, 40, 2)    0           conv2d_18[0][0]                  
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 40, 40, 2)    0           activation_1[0][0]               
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 40, 40, 2)    0           dropout_1[0][0]                  
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 40, 40, 2)    0           activation_2[0][0]               
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 40, 2)    0           dropout_2[0][0]                  
==================================================================================================
Total params: 7,846,690
Trainable params: 7,846,690
Non-trainable params: 0
__________________________________________________________________________________________________
Analysing training image 0 out of 100 images
Analysing training image 1 out of 100 images
Analysing training image 2 out of 100 images
Analysing training image 3 out of 100 images
Analysing training image 4 out of 100 images
Analysing training image 5 out of 100 images
Analysing training image 6 out of 100 images
Analysing training image 7 out of 100 images
Analysing training image 8 out of 100 images
Analysing training image 9 out of 100 images
Analysing training image 10 out of 100 images
Analysing training image 11 out of 100 images
Analysing training image 12 out of 100 images
Analysing training image 13 out of 100 images
Analysing training image 14 out of 100 images
Analysing training image 15 out of 100 images
Analysing training image 16 out of 100 images
Analysing training image 17 out of 100 images
Analysing training image 18 out of 100 images
Analysing training image 19 out of 100 images
Analysing training image 20 out of 100 images
Analysing training image 21 out of 100 images
Analysing training image 22 out of 100 images
Analysing training image 23 out of 100 images
Analysing training image 24 out of 100 images
Analysing training image 25 out of 100 images
Analysing training image 26 out of 100 images
Analysing training image 27 out of 100 images
Analysing training image 28 out of 100 images
Analysing training image 29 out of 100 images
Analysing training image 30 out of 100 images
Analysing training image 31 out of 100 images
Analysing training image 32 out of 100 images
Analysing training image 33 out of 100 images
Analysing training image 34 out of 100 images
Analysing training image 35 out of 100 images
Analysing training image 36 out of 100 images
Analysing training image 37 out of 100 images
Analysing training image 38 out of 100 images
Analysing training image 39 out of 100 images
Analysing training image 40 out of 100 images
Analysing training image 41 out of 100 images
Analysing training image 42 out of 100 images
Analysing training image 43 out of 100 images
Analysing training image 44 out of 100 images
Analysing training image 45 out of 100 images
Analysing training image 46 out of 100 images
Analysing training image 47 out of 100 images
Analysing training image 48 out of 100 images
Analysing training image 49 out of 100 images
Analysing training image 50 out of 100 images
Analysing training image 51 out of 100 images
Analysing training image 52 out of 100 images
Analysing training image 53 out of 100 images
Analysing training image 54 out of 100 images
Analysing training image 55 out of 100 images
Analysing training image 56 out of 100 images
Analysing training image 57 out of 100 images
Analysing training image 58 out of 100 images
Analysing training image 59 out of 100 images
Analysing training image 60 out of 100 images
Analysing training image 61 out of 100 images
Analysing training image 62 out of 100 images
Analysing training image 63 out of 100 images
Analysing training image 64 out of 100 images
Analysing training image 65 out of 100 images
Analysing training image 66 out of 100 images
Analysing training image 67 out of 100 images
Analysing training image 68 out of 100 images
Analysing training image 69 out of 100 images
Analysing training image 70 out of 100 images
Analysing training image 71 out of 100 images
Analysing training image 72 out of 100 images
Analysing training image 73 out of 100 images
Analysing training image 74 out of 100 images
Analysing training image 75 out of 100 images
Analysing training image 76 out of 100 images
Analysing training image 77 out of 100 images
Analysing training image 78 out of 100 images
Analysing training image 79 out of 100 images
Analysing training image 80 out of 100 images
Analysing training image 81 out of 100 images
Analysing training image 82 out of 100 images
Analysing training image 83 out of 100 images
Analysing training image 84 out of 100 images
Analysing training image 85 out of 100 images
Analysing training image 86 out of 100 images
Analysing training image 87 out of 100 images
Analysing training image 88 out of 100 images
Analysing training image 89 out of 100 images
Analysing training image 90 out of 100 images
Analysing training image 91 out of 100 images
Analysing training image 92 out of 100 images
Analysing training image 93 out of 100 images
Analysing training image 94 out of 100 images
Analysing training image 95 out of 100 images
Analysing training image 96 out of 100 images
Analysing training image 97 out of 100 images
Analysing training image 98 out of 100 images
Analysing training image 99 out of 100 images
Train on 4800 samples, validate on 1200 samples
Epoch 1/20

 300/4800 [>.............................] - ETA: 1:26 - loss: 0.6864 - acc: 0.7869
 600/4800 [==>...........................] - ETA: 41s - loss: 0.6878 - acc: 0.8094 
 900/4800 [====>.........................] - ETA: 26s - loss: 0.6882 - acc: 0.8349
1200/4800 [======>.......................] - ETA: 18s - loss: 0.6871 - acc: 0.8446
1500/4800 [========>.....................] - ETA: 14s - loss: 0.6846 - acc: 0.8580
1800/4800 [==========>...................] - ETA: 10s - loss: 0.6853 - acc: 0.8656
2100/4800 [============>.................] - ETA: 8s - loss: 0.6851 - acc: 0.8679 
2400/4800 [==============>...............] - ETA: 6s - loss: 0.6849 - acc: 0.8682
2700/4800 [===============>..............] - ETA: 5s - loss: 0.6848 - acc: 0.8726
3000/4800 [=================>............] - ETA: 4s - loss: 0.6838 - acc: 0.8758
3300/4800 [===================>..........] - ETA: 3s - loss: 0.6838 - acc: 0.8766
3600/4800 [=====================>........] - ETA: 2s - loss: 0.6839 - acc: 0.8785
3900/4800 [=======================>......] - ETA: 1s - loss: 0.6831 - acc: 0.8804
4200/4800 [=========================>....] - ETA: 1s - loss: 0.6826 - acc: 0.8804
4500/4800 [===========================>..] - ETA: 0s - loss: 0.6826 - acc: 0.8810
4800/4800 [==============================] - 8s 2ms/step - loss: 0.6821 - acc: 0.8820 - val_loss: 0.6760 - val_acc: 0.8971
Epoch 2/20

 300/4800 [>.............................] - ETA: 1s - loss: 0.6744 - acc: 0.8888
 600/4800 [==>...........................] - ETA: 1s - loss: 0.6709 - acc: 0.8941
 900/4800 [====>.........................] - ETA: 1s - loss: 0.6723 - acc: 0.8929
1200/4800 [======>.......................] - ETA: 1s - loss: 0.6721 - acc: 0.8952
1500/4800 [========>.....................] - ETA: 1s - loss: 0.6715 - acc: 0.8983
1800/4800 [==========>...................] - ETA: 1s - loss: 0.6699 - acc: 0.8995
2100/4800 [============>.................] - ETA: 1s - loss: 0.6676 - acc: 0.8957
2400/4800 [==============>...............] - ETA: 1s - loss: 0.6639 - acc: 0.8951
2700/4800 [===============>..............] - ETA: 1s - loss: 0.6599 - acc: 0.8960
3000/4800 [=================>............] - ETA: 0s - loss: 0.6577 - acc: 0.8959
3300/4800 [===================>..........] - ETA: 0s - loss: 0.6559 - acc: 0.8962
3600/4800 [=====================>........] - ETA: 0s - loss: 0.6551 - acc: 0.8948
3900/4800 [=======================>......] - ETA: 0s - loss: 0.6522 - acc: 0.8955
4200/4800 [=========================>....] - ETA: 0s - loss: 0.6500 - acc: 0.8969
4500/4800 [===========================>..] - ETA: 0s - loss: 0.6492 - acc: 0.8955
4800/4800 [==============================] - 3s 546us/step - loss: 0.6476 - acc: 0.8964 - val_loss: 0.5881 - val_acc: 0.8971
Epoch 3/20

 300/4800 [>.............................] - ETA: 1s - loss: 0.6256 - acc: 0.9080
 600/4800 [==>...........................] - ETA: 1s - loss: 0.6233 - acc: 0.9076
 900/4800 [====>.........................] - ETA: 1s - loss: 0.6237 - acc: 0.9075
1200/4800 [======>.......................] - ETA: 1s - loss: 0.6255 - acc: 0.9048
1500/4800 [========>.....................] - ETA: 1s - loss: 0.6270 - acc: 0.9017
1800/4800 [==========>...................] - ETA: 1s - loss: 0.6266 - acc: 0.9009
2100/4800 [============>.................] - ETA: 1s - loss: 0.6271 - acc: 0.8992
2400/4800 [==============>...............] - ETA: 1s - loss: 0.6274 - acc: 0.8983
2700/4800 [===============>..............] - ETA: 1s - loss: 0.6273 - acc: 0.8977
3000/4800 [=================>............] - ETA: 0s - loss: 0.6269 - acc: 0.8972
3300/4800 [===================>..........] - ETA: 0s - loss: 0.6258 - acc: 0.8980
3600/4800 [=====================>........] - ETA: 0s - loss: 0.6261 - acc: 0.8973
3900/4800 [=======================>......] - ETA: 0s - loss: 0.6260 - acc: 0.8977
4200/4800 [=========================>....] - ETA: 0s - loss: 0.6255 - acc: 0.8972
4500/4800 [===========================>..] - ETA: 0s - loss: 0.6247 - acc: 0.8973
4800/4800 [==============================] - 3s 560us/step - loss: 0.6245 - acc: 0.8964 - val_loss: 0.5574 - val_acc: 0.8971
Epoch 4/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.6122 - acc: 0.9171
 600/4800 [==>...........................] - ETA: 2s - loss: 0.6175 - acc: 0.9104
 900/4800 [====>.........................] - ETA: 1s - loss: 0.6200 - acc: 0.8995
1200/4800 [======>.......................] - ETA: 1s - loss: 0.6194 - acc: 0.8999
1500/4800 [========>.....................] - ETA: 1s - loss: 0.6199 - acc: 0.8973
1800/4800 [==========>...................] - ETA: 1s - loss: 0.6208 - acc: 0.8946
2100/4800 [============>.................] - ETA: 1s - loss: 0.6202 - acc: 0.8979
2400/4800 [==============>...............] - ETA: 1s - loss: 0.6200 - acc: 0.8972
2700/4800 [===============>..............] - ETA: 1s - loss: 0.6189 - acc: 0.8993
3000/4800 [=================>............] - ETA: 0s - loss: 0.6189 - acc: 0.8977
3300/4800 [===================>..........] - ETA: 0s - loss: 0.6184 - acc: 0.8985
3600/4800 [=====================>........] - ETA: 0s - loss: 0.6182 - acc: 0.8980
3900/4800 [=======================>......] - ETA: 0s - loss: 0.6182 - acc: 0.8979
4200/4800 [=========================>....] - ETA: 0s - loss: 0.6184 - acc: 0.8979
4500/4800 [===========================>..] - ETA: 0s - loss: 0.6186 - acc: 0.8970
4800/4800 [==============================] - 3s 546us/step - loss: 0.6191 - acc: 0.8965 - val_loss: 0.5478 - val_acc: 0.8971
Epoch 5/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.6158 - acc: 0.8967
 600/4800 [==>...........................] - ETA: 2s - loss: 0.6133 - acc: 0.9063
 900/4800 [====>.........................] - ETA: 1s - loss: 0.6140 - acc: 0.8991
1200/4800 [======>.......................] - ETA: 1s - loss: 0.6159 - acc: 0.9004
1500/4800 [========>.....................] - ETA: 1s - loss: 0.6148 - acc: 0.9018
1800/4800 [==========>...................] - ETA: 1s - loss: 0.6155 - acc: 0.8988
2100/4800 [============>.................] - ETA: 1s - loss: 0.6155 - acc: 0.8982
2400/4800 [==============>...............] - ETA: 1s - loss: 0.6154 - acc: 0.8990
2700/4800 [===============>..............] - ETA: 1s - loss: 0.6150 - acc: 0.8989
3000/4800 [=================>............] - ETA: 0s - loss: 0.6150 - acc: 0.8988
3300/4800 [===================>..........] - ETA: 0s - loss: 0.6142 - acc: 0.9003
3600/4800 [=====================>........] - ETA: 0s - loss: 0.6142 - acc: 0.9001
3900/4800 [=======================>......] - ETA: 0s - loss: 0.6142 - acc: 0.9000
4200/4800 [=========================>....] - ETA: 0s - loss: 0.6141 - acc: 0.8992
4500/4800 [===========================>..] - ETA: 0s - loss: 0.6135 - acc: 0.8987
4800/4800 [==============================] - 3s 550us/step - loss: 0.6145 - acc: 0.8965 - val_loss: 0.5328 - val_acc: 0.8971
Epoch 6/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.6112 - acc: 0.9017
 600/4800 [==>...........................] - ETA: 2s - loss: 0.6093 - acc: 0.8950
 900/4800 [====>.........................] - ETA: 1s - loss: 0.6098 - acc: 0.8917
1200/4800 [======>.......................] - ETA: 1s - loss: 0.6074 - acc: 0.8932
1500/4800 [========>.....................] - ETA: 1s - loss: 0.6073 - acc: 0.8955
1800/4800 [==========>...................] - ETA: 1s - loss: 0.6059 - acc: 0.8973
2100/4800 [============>.................] - ETA: 1s - loss: 0.6044 - acc: 0.8998
2400/4800 [==============>...............] - ETA: 1s - loss: 0.6050 - acc: 0.8981
2700/4800 [===============>..............] - ETA: 1s - loss: 0.6051 - acc: 0.8988
3000/4800 [=================>............] - ETA: 0s - loss: 0.6048 - acc: 0.8982
3300/4800 [===================>..........] - ETA: 0s - loss: 0.6048 - acc: 0.8981
3600/4800 [=====================>........] - ETA: 0s - loss: 0.6052 - acc: 0.8982
3900/4800 [=======================>......] - ETA: 0s - loss: 0.6051 - acc: 0.8984
4200/4800 [=========================>....] - ETA: 0s - loss: 0.6051 - acc: 0.8974
4500/4800 [===========================>..] - ETA: 0s - loss: 0.6054 - acc: 0.8966
4800/4800 [==============================] - 3s 560us/step - loss: 0.6053 - acc: 0.8965 - val_loss: 0.4338 - val_acc: 0.8971
Epoch 7/20

 300/4800 [>.............................] - ETA: 1s - loss: 0.6120 - acc: 0.8720
 600/4800 [==>...........................] - ETA: 1s - loss: 0.6088 - acc: 0.8875
 900/4800 [====>.........................] - ETA: 1s - loss: 0.6054 - acc: 0.8911
1200/4800 [======>.......................] - ETA: 1s - loss: 0.6034 - acc: 0.8933
1500/4800 [========>.....................] - ETA: 1s - loss: 0.6035 - acc: 0.8904
1800/4800 [==========>...................] - ETA: 1s - loss: 0.6019 - acc: 0.8932
2100/4800 [============>.................] - ETA: 1s - loss: 0.6008 - acc: 0.8965
2400/4800 [==============>...............] - ETA: 1s - loss: 0.6001 - acc: 0.8968
2700/4800 [===============>..............] - ETA: 1s - loss: 0.6005 - acc: 0.8956
3000/4800 [=================>............] - ETA: 0s - loss: 0.6004 - acc: 0.8965
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5993 - acc: 0.8983
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5997 - acc: 0.8965
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5992 - acc: 0.8962
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5989 - acc: 0.8961
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5985 - acc: 0.8957
4800/4800 [==============================] - 3s 553us/step - loss: 0.5984 - acc: 0.8965 - val_loss: 0.4192 - val_acc: 0.8971
Epoch 8/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5924 - acc: 0.9035
 600/4800 [==>...........................] - ETA: 1s - loss: 0.5940 - acc: 0.8996
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5944 - acc: 0.9000
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5947 - acc: 0.9002
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5957 - acc: 0.8993
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5953 - acc: 0.9017
2100/4800 [============>.................] - ETA: 1s - loss: 0.5960 - acc: 0.8988
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5963 - acc: 0.8978
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5952 - acc: 0.8976
3000/4800 [=================>............] - ETA: 0s - loss: 0.5950 - acc: 0.8970
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5951 - acc: 0.8971
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5954 - acc: 0.8967
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5959 - acc: 0.8952
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5956 - acc: 0.8958
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5955 - acc: 0.8962
4800/4800 [==============================] - 3s 551us/step - loss: 0.5956 - acc: 0.8965 - val_loss: 0.3891 - val_acc: 0.8971
Epoch 9/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5941 - acc: 0.8942
 600/4800 [==>...........................] - ETA: 2s - loss: 0.5955 - acc: 0.8944
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5958 - acc: 0.8932
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5944 - acc: 0.8998
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5940 - acc: 0.9005
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5947 - acc: 0.9002
2100/4800 [============>.................] - ETA: 1s - loss: 0.5931 - acc: 0.9013
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5940 - acc: 0.8994
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5941 - acc: 0.8963
3000/4800 [=================>............] - ETA: 0s - loss: 0.5944 - acc: 0.8957
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5943 - acc: 0.8966
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5941 - acc: 0.8968
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5943 - acc: 0.8961
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5947 - acc: 0.8955
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5947 - acc: 0.8961
4800/4800 [==============================] - 3s 552us/step - loss: 0.5948 - acc: 0.8965 - val_loss: 0.4311 - val_acc: 0.8971
Epoch 10/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5924 - acc: 0.9048
 600/4800 [==>...........................] - ETA: 2s - loss: 0.5949 - acc: 0.8951
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5950 - acc: 0.8924
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5951 - acc: 0.8946
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5945 - acc: 0.8966
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5944 - acc: 0.8958
2100/4800 [============>.................] - ETA: 1s - loss: 0.5933 - acc: 0.9004
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5941 - acc: 0.8983
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5936 - acc: 0.8997
3000/4800 [=================>............] - ETA: 0s - loss: 0.5941 - acc: 0.8971
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5949 - acc: 0.8955
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5942 - acc: 0.8949
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5942 - acc: 0.8965
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5946 - acc: 0.8956
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5941 - acc: 0.8964
4800/4800 [==============================] - 3s 557us/step - loss: 0.5936 - acc: 0.8965 - val_loss: 0.3883 - val_acc: 0.8971
Epoch 11/20

 300/4800 [>.............................] - ETA: 1s - loss: 0.5901 - acc: 0.9075
 600/4800 [==>...........................] - ETA: 1s - loss: 0.5896 - acc: 0.9032
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5890 - acc: 0.9056
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5876 - acc: 0.9009
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5907 - acc: 0.8994
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5917 - acc: 0.8976
2100/4800 [============>.................] - ETA: 1s - loss: 0.5913 - acc: 0.9000
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5918 - acc: 0.8959
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5924 - acc: 0.8943
3000/4800 [=================>............] - ETA: 0s - loss: 0.5928 - acc: 0.8954
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5931 - acc: 0.8966
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5925 - acc: 0.8970
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5922 - acc: 0.8952
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5920 - acc: 0.8962
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5920 - acc: 0.8964
4800/4800 [==============================] - 3s 542us/step - loss: 0.5919 - acc: 0.8965 - val_loss: 0.3795 - val_acc: 0.8971
Epoch 12/20

 300/4800 [>.............................] - ETA: 1s - loss: 0.6012 - acc: 0.8860
 600/4800 [==>...........................] - ETA: 1s - loss: 0.5975 - acc: 0.8951
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5955 - acc: 0.8968
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5951 - acc: 0.8961
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5939 - acc: 0.8971
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5940 - acc: 0.8972
2100/4800 [============>.................] - ETA: 1s - loss: 0.5930 - acc: 0.8998
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5937 - acc: 0.8967
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5937 - acc: 0.8945
3000/4800 [=================>............] - ETA: 0s - loss: 0.5934 - acc: 0.8963
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5926 - acc: 0.8990
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5926 - acc: 0.8997
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5929 - acc: 0.8975
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5932 - acc: 0.8962
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5929 - acc: 0.8956
4800/4800 [==============================] - 3s 550us/step - loss: 0.5923 - acc: 0.8965 - val_loss: 0.3880 - val_acc: 0.8971
Epoch 13/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5916 - acc: 0.8945
 600/4800 [==>...........................] - ETA: 2s - loss: 0.5904 - acc: 0.8983
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5941 - acc: 0.8976
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5949 - acc: 0.8960
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5939 - acc: 0.8965
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5934 - acc: 0.8985
2100/4800 [============>.................] - ETA: 1s - loss: 0.5931 - acc: 0.9003
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5923 - acc: 0.9019
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5925 - acc: 0.9030
3000/4800 [=================>............] - ETA: 0s - loss: 0.5922 - acc: 0.9028
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5923 - acc: 0.9021
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5929 - acc: 0.8993
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5923 - acc: 0.9013
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5919 - acc: 0.8996
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5923 - acc: 0.8984
4800/4800 [==============================] - 3s 549us/step - loss: 0.5926 - acc: 0.8965 - val_loss: 0.4035 - val_acc: 0.8971
Epoch 14/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5931 - acc: 0.8844
 600/4800 [==>...........................] - ETA: 2s - loss: 0.5904 - acc: 0.8922
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5909 - acc: 0.8869
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5921 - acc: 0.8842
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5919 - acc: 0.8893
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5927 - acc: 0.8874
2100/4800 [============>.................] - ETA: 1s - loss: 0.5923 - acc: 0.8913
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5920 - acc: 0.8929
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5910 - acc: 0.8936
3000/4800 [=================>............] - ETA: 0s - loss: 0.5911 - acc: 0.8942
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5910 - acc: 0.8943
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5908 - acc: 0.8945
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5912 - acc: 0.8946
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5907 - acc: 0.8955
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5909 - acc: 0.8954
4800/4800 [==============================] - 3s 552us/step - loss: 0.5908 - acc: 0.8965 - val_loss: 0.3984 - val_acc: 0.8971
Epoch 15/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5864 - acc: 0.8945
 600/4800 [==>...........................] - ETA: 2s - loss: 0.5895 - acc: 0.8880
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5912 - acc: 0.8919
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5899 - acc: 0.8972
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5893 - acc: 0.8974
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5897 - acc: 0.8978
2100/4800 [============>.................] - ETA: 1s - loss: 0.5888 - acc: 0.8997
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5895 - acc: 0.8991
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5895 - acc: 0.9018
3000/4800 [=================>............] - ETA: 0s - loss: 0.5895 - acc: 0.9001
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5897 - acc: 0.8995
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5892 - acc: 0.8999
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5896 - acc: 0.8987
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5899 - acc: 0.8982
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5898 - acc: 0.8974
4800/4800 [==============================] - 3s 542us/step - loss: 0.5901 - acc: 0.8965 - val_loss: 0.3850 - val_acc: 0.8971
Epoch 16/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5982 - acc: 0.8821
 600/4800 [==>...........................] - ETA: 2s - loss: 0.5955 - acc: 0.8813
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5954 - acc: 0.8871
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5931 - acc: 0.8834
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5912 - acc: 0.8882
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5892 - acc: 0.8921
2100/4800 [============>.................] - ETA: 1s - loss: 0.5892 - acc: 0.8936
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5896 - acc: 0.8929
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5897 - acc: 0.8930
3000/4800 [=================>............] - ETA: 0s - loss: 0.5893 - acc: 0.8918
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5897 - acc: 0.8927
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5893 - acc: 0.8938
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5893 - acc: 0.8939
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5889 - acc: 0.8952
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5890 - acc: 0.8959
4800/4800 [==============================] - 3s 552us/step - loss: 0.5894 - acc: 0.8965 - val_loss: 0.3804 - val_acc: 0.8971
Epoch 17/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5881 - acc: 0.8954
 600/4800 [==>...........................] - ETA: 2s - loss: 0.5866 - acc: 0.9062
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5889 - acc: 0.9037
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5891 - acc: 0.9047
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5897 - acc: 0.9028
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5881 - acc: 0.9024
2100/4800 [============>.................] - ETA: 1s - loss: 0.5876 - acc: 0.9010
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5874 - acc: 0.9014
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5869 - acc: 0.9031
3000/4800 [=================>............] - ETA: 0s - loss: 0.5870 - acc: 0.9031
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5871 - acc: 0.9018
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5882 - acc: 0.8993
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5882 - acc: 0.8992
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5884 - acc: 0.8976
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5888 - acc: 0.8968
4800/4800 [==============================] - 3s 558us/step - loss: 0.5889 - acc: 0.8965 - val_loss: 0.3838 - val_acc: 0.8971
Epoch 18/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5868 - acc: 0.9162
 600/4800 [==>...........................] - ETA: 2s - loss: 0.5839 - acc: 0.9196
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5848 - acc: 0.9076
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5864 - acc: 0.9019
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5873 - acc: 0.9030
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5884 - acc: 0.9019
2100/4800 [============>.................] - ETA: 1s - loss: 0.5887 - acc: 0.9022
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5877 - acc: 0.9034
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5880 - acc: 0.9024
3000/4800 [=================>............] - ETA: 0s - loss: 0.5881 - acc: 0.9008
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5886 - acc: 0.9002
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5885 - acc: 0.8978
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5881 - acc: 0.8977
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5880 - acc: 0.8968
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5883 - acc: 0.8964
4800/4800 [==============================] - 3s 557us/step - loss: 0.5883 - acc: 0.8965 - val_loss: 0.3784 - val_acc: 0.8971
Epoch 19/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5858 - acc: 0.9111
 600/4800 [==>...........................] - ETA: 2s - loss: 0.5904 - acc: 0.8940
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5885 - acc: 0.8960
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5854 - acc: 0.8982
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5848 - acc: 0.9021
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5868 - acc: 0.8998
2100/4800 [============>.................] - ETA: 1s - loss: 0.5871 - acc: 0.9011
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5876 - acc: 0.9006
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5880 - acc: 0.8990
3000/4800 [=================>............] - ETA: 0s - loss: 0.5871 - acc: 0.8996
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5878 - acc: 0.8996
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5878 - acc: 0.8995
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5877 - acc: 0.8988
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5872 - acc: 0.8993
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5876 - acc: 0.8982
4800/4800 [==============================] - 3s 544us/step - loss: 0.5881 - acc: 0.8965 - val_loss: 0.3863 - val_acc: 0.8971
Epoch 20/20

 300/4800 [>.............................] - ETA: 1s - loss: 0.5936 - acc: 0.8852
 600/4800 [==>...........................] - ETA: 1s - loss: 0.5896 - acc: 0.8942
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5893 - acc: 0.8918
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5888 - acc: 0.8909
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5865 - acc: 0.8936
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5873 - acc: 0.8978
2100/4800 [============>.................] - ETA: 1s - loss: 0.5863 - acc: 0.8982
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5858 - acc: 0.8965
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5857 - acc: 0.8969
3000/4800 [=================>............] - ETA: 0s - loss: 0.5867 - acc: 0.8963
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5870 - acc: 0.8965
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5872 - acc: 0.8961
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5877 - acc: 0.8959
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5877 - acc: 0.8957
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5876 - acc: 0.8970
4800/4800 [==============================] - 3s 543us/step - loss: 0.5879 - acc: 0.8965 - val_loss: 0.3457 - val_acc: 0.8971
C:\Anaconda3\lib\site-packages\h5py\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
Finished
