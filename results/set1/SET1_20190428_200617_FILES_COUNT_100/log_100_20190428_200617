----------------------------------
- Parameters.py                  -
----------------------------------
data_params = {
    "width"                 : 640,
    "height"                : 480,
    "labelled_train_db"     : 'data/labels.train.db',
    "labelled_train_dir"    : 'data/labelled.train/',
    "labelled_validate_db"  : 'data/labels.validate.db',
    "labelled_validate_dir" : 'data/labelled.validate/',
    "segmented_dir"         : 'data/segmented/'
}

model_params = {
    "num_classes" : 2,
    "batch_size"  : 300,
    "epochs"      : 20
}

hyper_params = {
    "max_training_images_count"    : 100,     # if value is -1 then take all training images
    "max_testing_images_count"     : -1,      # if value is -1 then take all training images
    "l2_regularisation"            : 0.0005,
    "dropout"                      : 0.50,
    "learning_rate"                : 0.0001,
    "percentage_train"             : 80,
    "windows_per_image_on_average" : 60,
    "window_size"                  : 40,
    "bee_radius"                   : 20,
    "min_bee_prob"                 : 0.80,
    "max_bee_prob"                 : 1.00,
    "min_bee_prct_window"          : 45.0,
    "bee_window_percentage"        : 20,
    "filters_count"                : 32,
    "kernel_size"                  : 3,
    "padding_to_remove"            : 4,
    "sliding_window_step"          : 2
}
----------------------------------
- Training                       -
----------------------------------
Data Parameters:
Key: width, Value: 640
Key: height, Value: 480
Key: labelled_train_db, Value: data/labels.train.db
Key: labelled_train_dir, Value: data/labelled.train/
Key: labelled_validate_db, Value: data/labels.validate.db
Key: labelled_validate_dir, Value: data/labelled.validate/
Key: segmented_dir, Value: data/segmented/
Model Parameters:
Key: num_classes, Value: 2
Key: batch_size, Value: 300
Key: epochs, Value: 20
Hyper Parameters:
Key: max_training_images_count, Value: 100
Key: max_testing_images_count, Value: -1
Key: l2_regularisation, Value: 0.0005
Key: dropout, Value: 0.5
Key: learning_rate, Value: 0.0001
Key: percentage_train, Value: 80
Key: windows_per_image_on_average, Value: 60
Key: window_size, Value: 40
Key: bee_radius, Value: 20
Key: min_bee_prob, Value: 0.8
Key: max_bee_prob, Value: 1.0
Key: min_bee_prct_window, Value: 45.0
Key: bee_window_percentage, Value: 20
Key: filters_count, Value: 32
Key: kernel_size, Value: 3
Key: padding_to_remove, Value: 4
Key: sliding_window_step, Value: 2
Index is 52
Index is 7
Index is 82
Index is 18
Index is 40
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 40, 40, 3)    0                                            
__________________________________________________________________________________________________
conv1_1 (Conv2D)                (None, 40, 40, 32)   896         input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 40, 40, 32)   9248        conv1_1[0][0]                    
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 20, 20, 32)   0           conv2d_1[0][0]                   
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 20, 20, 64)   18496       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 20, 20, 64)   36928       conv2d_2[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 10, 10, 64)   0           conv2d_3[0][0]                   
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 10, 10, 128)  73856       max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 10, 10, 128)  147584      conv2d_4[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 128)    0           conv2d_5[0][0]                   
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 5, 5, 256)    295168      max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 5, 5, 256)    590080      conv2d_6[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)  (None, 2, 2, 256)    0           conv2d_7[0][0]                   
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 2, 2, 512)    1180160     max_pooling2d_4[0][0]            
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 2, 2, 512)    2359808     conv2d_8[0][0]                   
__________________________________________________________________________________________________
up_sampling2d_1 (UpSampling2D)  (None, 4, 4, 512)    0           conv2d_9[0][0]                   
__________________________________________________________________________________________________
cropping2d_1 (Cropping2D)       (None, 4, 4, 256)    0           conv2d_7[0][0]                   
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 4, 4, 768)    0           up_sampling2d_1[0][0]            
                                                                 cropping2d_1[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 4, 4, 256)    1769728     concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 4, 4, 256)    590080      conv2d_10[0][0]                  
__________________________________________________________________________________________________
up_sampling2d_2 (UpSampling2D)  (None, 8, 8, 256)    0           conv2d_11[0][0]                  
__________________________________________________________________________________________________
cropping2d_2 (Cropping2D)       (None, 8, 8, 128)    0           conv2d_5[0][0]                   
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 8, 8, 384)    0           up_sampling2d_2[0][0]            
                                                                 cropping2d_2[0][0]               
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 8, 8, 128)    442496      concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 8, 8, 128)    147584      conv2d_12[0][0]                  
__________________________________________________________________________________________________
up_sampling2d_3 (UpSampling2D)  (None, 16, 16, 128)  0           conv2d_13[0][0]                  
__________________________________________________________________________________________________
cropping2d_3 (Cropping2D)       (None, 16, 16, 64)   0           conv2d_3[0][0]                   
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 16, 16, 192)  0           up_sampling2d_3[0][0]            
                                                                 cropping2d_3[0][0]               
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 16, 16, 64)   110656      concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 16, 16, 64)   36928       conv2d_14[0][0]                  
__________________________________________________________________________________________________
up_sampling2d_4 (UpSampling2D)  (None, 32, 32, 64)   0           conv2d_15[0][0]                  
__________________________________________________________________________________________________
cropping2d_4 (Cropping2D)       (None, 32, 32, 32)   0           conv2d_1[0][0]                   
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 32, 32, 96)   0           up_sampling2d_4[0][0]            2019-04-28 20:06:46.535293: I T:\src\github\tensorflow\tensorflow\core\platform\cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2019-04-28 20:06:46.947088: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1405] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.8095
pciBusID: 0000:65:00.0
totalMemory: 8.00GiB freeMemory: 6.59GiB
2019-04-28 20:06:46.948368: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1484] Adding visible gpu devices: 0
2019-04-28 20:06:49.511501: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-04-28 20:06:49.512318: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:971]      0 
2019-04-28 20:06:49.512834: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:984] 0:   N 
2019-04-28 20:06:49.515697: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6360 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:65:00.0, compute capability: 6.1)

                                                                 cropping2d_4[0][0]               
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 32, 32, 32)   27680       concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 32, 32, 32)   9248        conv2d_16[0][0]                  
__________________________________________________________________________________________________
zero_padding2d_1 (ZeroPadding2D (None, 40, 40, 32)   0           conv2d_17[0][0]                  
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 40, 40, 2)    66          zero_padding2d_1[0][0]           
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 40, 40, 2)    0           conv2d_18[0][0]                  
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 40, 40, 2)    0           activation_1[0][0]               
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 40, 40, 2)    0           dropout_1[0][0]                  
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 40, 40, 2)    0           activation_2[0][0]               
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 40, 2)    0           dropout_2[0][0]                  
==================================================================================================
Total params: 7,846,690
Trainable params: 7,846,690
Non-trainable params: 0
__________________________________________________________________________________________________
Analysing training image 0 out of 100 images
Analysing training image 1 out of 100 images
Analysing training image 2 out of 100 images
Analysing training image 3 out of 100 images
Analysing training image 4 out of 100 images
Analysing training image 5 out of 100 images
Analysing training image 6 out of 100 images
Analysing training image 7 out of 100 images
Analysing training image 8 out of 100 images
Analysing training image 9 out of 100 images
Analysing training image 10 out of 100 images
Analysing training image 11 out of 100 images
Analysing training image 12 out of 100 images
Analysing training image 13 out of 100 images
Analysing training image 14 out of 100 images
Analysing training image 15 out of 100 images
Analysing training image 16 out of 100 images
Analysing training image 17 out of 100 images
Analysing training image 18 out of 100 images
Analysing training image 19 out of 100 images
Analysing training image 20 out of 100 images
Analysing training image 21 out of 100 images
Analysing training image 22 out of 100 images
Analysing training image 23 out of 100 images
Analysing training image 24 out of 100 images
Analysing training image 25 out of 100 images
Analysing training image 26 out of 100 images
Analysing training image 27 out of 100 images
Analysing training image 28 out of 100 images
Analysing training image 29 out of 100 images
Analysing training image 30 out of 100 images
Analysing training image 31 out of 100 images
Analysing training image 32 out of 100 images
Analysing training image 33 out of 100 images
Analysing training image 34 out of 100 images
Analysing training image 35 out of 100 images
Analysing training image 36 out of 100 images
Analysing training image 37 out of 100 images
Analysing training image 38 out of 100 images
Analysing training image 39 out of 100 images
Analysing training image 40 out of 100 images
Analysing training image 41 out of 100 images
Analysing training image 42 out of 100 images
Analysing training image 43 out of 100 images
Analysing training image 44 out of 100 images
Analysing training image 45 out of 100 images
Analysing training image 46 out of 100 images
Analysing training image 47 out of 100 images
Analysing training image 48 out of 100 images
Analysing training image 49 out of 100 images
Analysing training image 50 out of 100 images
Analysing training image 51 out of 100 images
Analysing training image 52 out of 100 images
Analysing training image 53 out of 100 images
Analysing training image 54 out of 100 images
Analysing training image 55 out of 100 images
Analysing training image 56 out of 100 images
Analysing training image 57 out of 100 images
Analysing training image 58 out of 100 images
Analysing training image 59 out of 100 images
Analysing training image 60 out of 100 images
Analysing training image 61 out of 100 images
Analysing training image 62 out of 100 images
Analysing training image 63 out of 100 images
Analysing training image 64 out of 100 images
Analysing training image 65 out of 100 images
Analysing training image 66 out of 100 images
Analysing training image 67 out of 100 images
Analysing training image 68 out of 100 images
Analysing training image 69 out of 100 images
Analysing training image 70 out of 100 images
Analysing training image 71 out of 100 images
Analysing training image 72 out of 100 images
Analysing training image 73 out of 100 images
Analysing training image 74 out of 100 images
Analysing training image 75 out of 100 images
Analysing training image 76 out of 100 images
Analysing training image 77 out of 100 images
Analysing training image 78 out of 100 images
Analysing training image 79 out of 100 images
Analysing training image 80 out of 100 images
Analysing training image 81 out of 100 images
Analysing training image 82 out of 100 images
Analysing training image 83 out of 100 images
Analysing training image 84 out of 100 images
Analysing training image 85 out of 100 images
Analysing training image 86 out of 100 images
Analysing training image 87 out of 100 images
Analysing training image 88 out of 100 images
Analysing training image 89 out of 100 images
Analysing training image 90 out of 100 images
Analysing training image 91 out of 100 images
Analysing training image 92 out of 100 images
Analysing training image 93 out of 100 images
Analysing training image 94 out of 100 images
Analysing training image 95 out of 100 images
Analysing training image 96 out of 100 images
Analysing training image 97 out of 100 images
Analysing training image 98 out of 100 images
Analysing training image 99 out of 100 images
Train on 4800 samples, validate on 1200 samples
Epoch 1/20

 300/4800 [>.............................] - ETA: 2:06 - loss: 0.6792 - acc: 0.8913
 600/4800 [==>...........................] - ETA: 1:00 - loss: 0.6836 - acc: 0.8899
 900/4800 [====>.........................] - ETA: 37s - loss: 0.6814 - acc: 0.8914 
1200/4800 [======>.......................] - ETA: 26s - loss: 0.6802 - acc: 0.8933
1500/4800 [========>.....................] - ETA: 19s - loss: 0.6774 - acc: 0.8935
1800/4800 [==========>...................] - ETA: 15s - loss: 0.6770 - acc: 0.8923
2100/4800 [============>.................] - ETA: 12s - loss: 0.6748 - acc: 0.8925
2400/4800 [==============>...............] - ETA: 9s - loss: 0.6727 - acc: 0.8947 
2700/4800 [===============>..............] - ETA: 7s - loss: 0.6721 - acc: 0.8903
3000/4800 [=================>............] - ETA: 5s - loss: 0.6704 - acc: 0.8880
3300/4800 [===================>..........] - ETA: 4s - loss: 0.6691 - acc: 0.8890
3600/4800 [=====================>........] - ETA: 3s - loss: 0.6676 - acc: 0.8908
3900/4800 [=======================>......] - ETA: 2s - loss: 0.6652 - acc: 0.8948
4200/4800 [=========================>....] - ETA: 1s - loss: 0.6628 - acc: 0.8956
4500/4800 [===========================>..] - ETA: 0s - loss: 0.6617 - acc: 0.8933
4800/4800 [==============================] - 11s 2ms/step - loss: 0.6591 - acc: 0.8950 - val_loss: 0.5543 - val_acc: 0.8927
Epoch 2/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.6195 - acc: 0.9034
 600/4800 [==>...........................] - ETA: 2s - loss: 0.6336 - acc: 0.8856
 900/4800 [====>.........................] - ETA: 1s - loss: 0.6304 - acc: 0.8891
1200/4800 [======>.......................] - ETA: 1s - loss: 0.6290 - acc: 0.8906
1500/4800 [========>.....................] - ETA: 1s - loss: 0.6294 - acc: 0.8879
1800/4800 [==========>...................] - ETA: 1s - loss: 0.6290 - acc: 0.8892
2100/4800 [============>.................] - ETA: 1s - loss: 0.6298 - acc: 0.8872
2400/4800 [==============>...............] - ETA: 1s - loss: 0.6287 - acc: 0.8905
2700/4800 [===============>..............] - ETA: 1s - loss: 0.6295 - acc: 0.8873
3000/4800 [=================>............] - ETA: 0s - loss: 0.6289 - acc: 0.8884
3300/4800 [===================>..........] - ETA: 0s - loss: 0.6289 - acc: 0.8882
3600/4800 [=====================>........] - ETA: 0s - loss: 0.6280 - acc: 0.8905
3900/4800 [=======================>......] - ETA: 0s - loss: 0.6278 - acc: 0.8913
4200/4800 [=========================>....] - ETA: 0s - loss: 0.6275 - acc: 0.8932
4500/4800 [===========================>..] - ETA: 0s - loss: 0.6266 - acc: 0.8951
4800/4800 [==============================] - 3s 532us/step - loss: 0.6263 - acc: 0.8956 - val_loss: 0.5593 - val_acc: 0.8927
Epoch 3/20

 300/4800 [>.............................] - ETA: 1s - loss: 0.6310 - acc: 0.8896
 600/4800 [==>...........................] - ETA: 1s - loss: 0.6308 - acc: 0.8875
 900/4800 [====>.........................] - ETA: 1s - loss: 0.6274 - acc: 0.8917
1200/4800 [======>.......................] - ETA: 1s - loss: 0.6243 - acc: 0.8928
1500/4800 [========>.....................] - ETA: 1s - loss: 0.6242 - acc: 0.8894
1800/4800 [==========>...................] - ETA: 1s - loss: 0.6243 - acc: 0.8909
2100/4800 [============>.................] - ETA: 1s - loss: 0.6235 - acc: 0.8920
2400/4800 [==============>...............] - ETA: 1s - loss: 0.6228 - acc: 0.8942
2700/4800 [===============>..............] - ETA: 0s - loss: 0.6214 - acc: 0.8954
3000/4800 [=================>............] - ETA: 0s - loss: 0.6216 - acc: 0.8956
3300/4800 [===================>..........] - ETA: 0s - loss: 0.6214 - acc: 0.8941
3600/4800 [=====================>........] - ETA: 0s - loss: 0.6216 - acc: 0.8954
3900/4800 [=======================>......] - ETA: 0s - loss: 0.6221 - acc: 0.8935
4200/4800 [=========================>....] - ETA: 0s - loss: 0.6217 - acc: 0.8947
4500/4800 [===========================>..] - ETA: 0s - loss: 0.6209 - acc: 0.8948
4800/4800 [==============================] - 3s 521us/step - loss: 0.6204 - acc: 0.8958 - val_loss: 0.5432 - val_acc: 0.8927
Epoch 4/20

 300/4800 [>.............................] - ETA: 1s - loss: 0.6196 - acc: 0.8856
 600/4800 [==>...........................] - ETA: 1s - loss: 0.6210 - acc: 0.8774
 900/4800 [====>.........................] - ETA: 1s - loss: 0.6181 - acc: 0.8878
1200/4800 [======>.......................] - ETA: 1s - loss: 0.6162 - acc: 0.8913
1500/4800 [========>.....................] - ETA: 1s - loss: 0.6164 - acc: 0.8937
1800/4800 [==========>...................] - ETA: 1s - loss: 0.6168 - acc: 0.8920
2100/4800 [============>.................] - ETA: 1s - loss: 0.6171 - acc: 0.8942
2400/4800 [==============>...............] - ETA: 1s - loss: 0.6173 - acc: 0.8938
2700/4800 [===============>..............] - ETA: 0s - loss: 0.6167 - acc: 0.8983
3000/4800 [=================>............] - ETA: 0s - loss: 0.6165 - acc: 0.8985
3300/4800 [===================>..........] - ETA: 0s - loss: 0.6167 - acc: 0.8981
3600/4800 [=====================>........] - ETA: 0s - loss: 0.6167 - acc: 0.8987
3900/4800 [=======================>......] - ETA: 0s - loss: 0.6168 - acc: 0.8979
4200/4800 [=========================>....] - ETA: 0s - loss: 0.6168 - acc: 0.8975
4500/4800 [===========================>..] - ETA: 0s - loss: 0.6170 - acc: 0.8971
4800/4800 [==============================] - 3s 521us/step - loss: 0.6174 - acc: 0.8958 - val_loss: 0.5428 - val_acc: 0.8927
Epoch 5/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.6094 - acc: 0.9196
 600/4800 [==>...........................] - ETA: 2s - loss: 0.6183 - acc: 0.8960
 900/4800 [====>.........................] - ETA: 1s - loss: 0.6204 - acc: 0.8928
1200/4800 [======>.......................] - ETA: 1s - loss: 0.6168 - acc: 0.8955
1500/4800 [========>.....................] - ETA: 1s - loss: 0.6171 - acc: 0.8949
1800/4800 [==========>...................] - ETA: 1s - loss: 0.6144 - acc: 0.8984
2100/4800 [============>.................] - ETA: 1s - loss: 0.6139 - acc: 0.8966
2400/4800 [==============>...............] - ETA: 1s - loss: 0.6142 - acc: 0.8961
2700/4800 [===============>..............] - ETA: 1s - loss: 0.6145 - acc: 0.8952
3000/4800 [=================>............] - ETA: 0s - loss: 0.6139 - acc: 0.8965
3300/4800 [===================>..........] - ETA: 0s - loss: 0.6135 - acc: 0.8967
3600/4800 [=====================>........] - ETA: 0s - loss: 0.6138 - acc: 0.8973
3900/4800 [=======================>......] - ETA: 0s - loss: 0.6140 - acc: 0.8966
4200/4800 [=========================>....] - ETA: 0s - loss: 0.6142 - acc: 0.8957
4500/4800 [===========================>..] - ETA: 0s - loss: 0.6139 - acc: 0.8957
4800/4800 [==============================] - 3s 541us/step - loss: 0.6138 - acc: 0.8957 - val_loss: 0.5087 - val_acc: 0.8928
Epoch 6/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.6081 - acc: 0.9139
 600/4800 [==>...........................] - ETA: 2s - loss: 0.6139 - acc: 0.8962
 900/4800 [====>.........................] - ETA: 1s - loss: 0.6117 - acc: 0.8943
1200/4800 [======>.......................] - ETA: 1s - loss: 0.6121 - acc: 0.8893
1500/4800 [========>.....................] - ETA: 1s - loss: 0.6119 - acc: 0.8914
1800/4800 [==========>...................] - ETA: 1s - loss: 0.6100 - acc: 0.8944
2100/4800 [============>.................] - ETA: 1s - loss: 0.6102 - acc: 0.8926
2400/4800 [==============>...............] - ETA: 1s - loss: 0.6104 - acc: 0.8913
2700/4800 [===============>..............] - ETA: 1s - loss: 0.6109 - acc: 0.8949
3000/4800 [=================>............] - ETA: 0s - loss: 0.6108 - acc: 0.8968
3300/4800 [===================>..........] - ETA: 0s - loss: 0.6104 - acc: 0.8974
3600/4800 [=====================>........] - ETA: 0s - loss: 0.6102 - acc: 0.8970
3900/4800 [=======================>......] - ETA: 0s - loss: 0.6103 - acc: 0.8969
4200/4800 [=========================>....] - ETA: 0s - loss: 0.6100 - acc: 0.8977
4500/4800 [===========================>..] - ETA: 0s - loss: 0.6096 - acc: 0.8967
4800/4800 [==============================] - 3s 551us/step - loss: 0.6093 - acc: 0.8959 - val_loss: 0.5039 - val_acc: 0.8932
Epoch 7/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.6082 - acc: 0.8956
 600/4800 [==>...........................] - ETA: 2s - loss: 0.6077 - acc: 0.8841
 900/4800 [====>.........................] - ETA: 1s - loss: 0.6022 - acc: 0.8889
1200/4800 [======>.......................] - ETA: 1s - loss: 0.6020 - acc: 0.8911
1500/4800 [========>.....................] - ETA: 1s - loss: 0.6019 - acc: 0.8887
1800/4800 [==========>...................] - ETA: 1s - loss: 0.6021 - acc: 0.8885
2100/4800 [============>.................] - ETA: 1s - loss: 0.6028 - acc: 0.8861
2400/4800 [==============>...............] - ETA: 1s - loss: 0.6012 - acc: 0.8889
2700/4800 [===============>..............] - ETA: 1s - loss: 0.6006 - acc: 0.8905
3000/4800 [=================>............] - ETA: 0s - loss: 0.6010 - acc: 0.8911
3300/4800 [===================>..........] - ETA: 0s - loss: 0.6019 - acc: 0.8927
3600/4800 [=====================>........] - ETA: 0s - loss: 0.6015 - acc: 0.8945
3900/4800 [=======================>......] - ETA: 0s - loss: 0.6021 - acc: 0.8944
4200/4800 [=========================>....] - ETA: 0s - loss: 0.6018 - acc: 0.8952
4500/4800 [===========================>..] - ETA: 0s - loss: 0.6020 - acc: 0.8948
4800/4800 [==============================] - 3s 554us/step - loss: 0.6017 - acc: 0.8960 - val_loss: 0.4675 - val_acc: 0.8928
Epoch 8/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5990 - acc: 0.9010
 600/4800 [==>...........................] - ETA: 2s - loss: 0.5975 - acc: 0.8971
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5976 - acc: 0.8999
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5999 - acc: 0.8939
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5974 - acc: 0.8942
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5992 - acc: 0.8913
2100/4800 [============>.................] - ETA: 1s - loss: 0.5985 - acc: 0.8910
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5978 - acc: 0.8921
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5980 - acc: 0.8934
3000/4800 [=================>............] - ETA: 0s - loss: 0.5980 - acc: 0.8938
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5969 - acc: 0.8965
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5970 - acc: 0.8959
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5964 - acc: 0.8963
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5961 - acc: 0.8966
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5964 - acc: 0.8970
4800/4800 [==============================] - 3s 542us/step - loss: 0.5970 - acc: 0.8959 - val_loss: 0.4452 - val_acc: 0.8929
Epoch 9/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5998 - acc: 0.8981
 600/4800 [==>...........................] - ETA: 2s - loss: 0.5967 - acc: 0.8982
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5966 - acc: 0.8954
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5958 - acc: 0.8983
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5952 - acc: 0.9006
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5939 - acc: 0.9036
2100/4800 [============>.................] - ETA: 1s - loss: 0.5941 - acc: 0.9021
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5941 - acc: 0.9035
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5955 - acc: 0.9001
3000/4800 [=================>............] - ETA: 0s - loss: 0.5951 - acc: 0.9008
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5960 - acc: 0.8989
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5960 - acc: 0.8981
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5960 - acc: 0.8981
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5963 - acc: 0.8966
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5960 - acc: 0.8961
4800/4800 [==============================] - 3s 547us/step - loss: 0.5960 - acc: 0.8959 - val_loss: 0.4261 - val_acc: 0.8931
Epoch 10/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5912 - acc: 0.9096
 600/4800 [==>...........................] - ETA: 1s - loss: 0.5890 - acc: 0.9086
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5927 - acc: 0.8998
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5932 - acc: 0.8974
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5944 - acc: 0.8921
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5944 - acc: 0.8945
2100/4800 [============>.................] - ETA: 1s - loss: 0.5949 - acc: 0.8962
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5942 - acc: 0.8935
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5942 - acc: 0.8951
3000/4800 [=================>............] - ETA: 0s - loss: 0.5942 - acc: 0.8943
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5940 - acc: 0.8949
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5941 - acc: 0.8961
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5941 - acc: 0.8954
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5937 - acc: 0.8968
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5938 - acc: 0.8971
4800/4800 [==============================] - 3s 542us/step - loss: 0.5941 - acc: 0.8960 - val_loss: 0.3894 - val_acc: 0.8932
Epoch 11/20

 300/4800 [>.............................] - ETA: 1s - loss: 0.5962 - acc: 0.9019
 600/4800 [==>...........................] - ETA: 1s - loss: 0.5921 - acc: 0.9069
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5951 - acc: 0.8950
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5953 - acc: 0.8895
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5939 - acc: 0.8977
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5942 - acc: 0.8975
2100/4800 [============>.................] - ETA: 1s - loss: 0.5939 - acc: 0.8990
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5944 - acc: 0.8974
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5948 - acc: 0.8963
3000/4800 [=================>............] - ETA: 0s - loss: 0.5946 - acc: 0.8972
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5944 - acc: 0.8951
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5934 - acc: 0.8957
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5936 - acc: 0.8937
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5937 - acc: 0.8945
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5938 - acc: 0.8953
4800/4800 [==============================] - 2s 520us/step - loss: 0.5932 - acc: 0.8960 - val_loss: 0.4076 - val_acc: 0.8932
Epoch 12/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5830 - acc: 0.8951
 600/4800 [==>...........................] - ETA: 1s - loss: 0.5888 - acc: 0.8893
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5899 - acc: 0.8895
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5921 - acc: 0.8884
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5936 - acc: 0.8881
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5917 - acc: 0.8927
2100/4800 [============>.................] - ETA: 1s - loss: 0.5927 - acc: 0.8899
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5933 - acc: 0.8912
2700/4800 [===============>..............] - ETA: 0s - loss: 0.5931 - acc: 0.8927
3000/4800 [=================>............] - ETA: 0s - loss: 0.5926 - acc: 0.8941
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5921 - acc: 0.8958
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5928 - acc: 0.8961
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5929 - acc: 0.8967
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5926 - acc: 0.8977
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5918 - acc: 0.8977
4800/4800 [==============================] - 3s 525us/step - loss: 0.5922 - acc: 0.8960 - val_loss: 0.3790 - val_acc: 0.8932
Epoch 13/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5912 - acc: 0.8875
 600/4800 [==>...........................] - ETA: 1s - loss: 0.5887 - acc: 0.9008
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5855 - acc: 0.9058
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5874 - acc: 0.9029
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5890 - acc: 0.9008
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5899 - acc: 0.9015
2100/4800 [============>.................] - ETA: 1s - loss: 0.5908 - acc: 0.9010
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5918 - acc: 0.9003
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5922 - acc: 0.8986
3000/4800 [=================>............] - ETA: 0s - loss: 0.5923 - acc: 0.8956
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5914 - acc: 0.8959
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5905 - acc: 0.8960
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5909 - acc: 0.8965
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5908 - acc: 0.8963
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5913 - acc: 0.8972
4800/4800 [==============================] - 3s 532us/step - loss: 0.5915 - acc: 0.8960 - val_loss: 0.3910 - val_acc: 0.8933
Epoch 14/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5958 - acc: 0.8943
 600/4800 [==>...........................] - ETA: 1s - loss: 0.5930 - acc: 0.8916
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5917 - acc: 0.8964
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5911 - acc: 0.8959
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5913 - acc: 0.8970
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5910 - acc: 0.8974
2100/4800 [============>.................] - ETA: 1s - loss: 0.5904 - acc: 0.8976
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5900 - acc: 0.8980
2700/4800 [===============>..............] - ETA: 0s - loss: 0.5902 - acc: 0.8972
3000/4800 [=================>............] - ETA: 0s - loss: 0.5908 - acc: 0.8968
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5898 - acc: 0.8977
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5900 - acc: 0.8981
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5903 - acc: 0.8981
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5908 - acc: 0.8972
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5909 - acc: 0.8964
4800/4800 [==============================] - 3s 536us/step - loss: 0.5907 - acc: 0.8960 - val_loss: 0.3772 - val_acc: 0.8933
Epoch 15/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5911 - acc: 0.8941
 600/4800 [==>...........................] - ETA: 1s - loss: 0.5936 - acc: 0.8879
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5919 - acc: 0.8924
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5905 - acc: 0.8895
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5911 - acc: 0.8914
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5911 - acc: 0.8938
2100/4800 [============>.................] - ETA: 1s - loss: 0.5892 - acc: 0.8980
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5898 - acc: 0.8999
2700/4800 [===============>..............] - ETA: 0s - loss: 0.5893 - acc: 0.8995
3000/4800 [=================>............] - ETA: 0s - loss: 0.5897 - acc: 0.8989
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5896 - acc: 0.8982
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5899 - acc: 0.8980
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5902 - acc: 0.8979
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5898 - acc: 0.8966
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5899 - acc: 0.8970
4800/4800 [==============================] - 3s 529us/step - loss: 0.5902 - acc: 0.8960 - val_loss: 0.3877 - val_acc: 0.8934
Epoch 16/20

 300/4800 [>.............................] - ETA: 1s - loss: 0.5885 - acc: 0.9066
 600/4800 [==>...........................] - ETA: 1s - loss: 0.5887 - acc: 0.8938
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5906 - acc: 0.8963
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5896 - acc: 0.9011
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5904 - acc: 0.8972
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5901 - acc: 0.8981
2100/4800 [============>.................] - ETA: 1s - loss: 0.5909 - acc: 0.8959
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5899 - acc: 0.8956
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5894 - acc: 0.8973
3000/4800 [=================>............] - ETA: 0s - loss: 0.5894 - acc: 0.8966
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5890 - acc: 0.8973
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5893 - acc: 0.8972
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5894 - acc: 0.8962
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5891 - acc: 0.8962
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5894 - acc: 0.8958
4800/4800 [==============================] - 3s 541us/step - loss: 0.5893 - acc: 0.8960 - val_loss: 0.3882 - val_acc: 0.8934
Epoch 17/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5877 - acc: 0.9074
 600/4800 [==>...........................] - ETA: 2s - loss: 0.5908 - acc: 0.9019
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5901 - acc: 0.9054
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5915 - acc: 0.8986
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5912 - acc: 0.8998
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5909 - acc: 0.8992
2100/4800 [============>.................] - ETA: 1s - loss: 0.5899 - acc: 0.9009
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5904 - acc: 0.9002
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5892 - acc: 0.8986
3000/4800 [=================>............] - ETA: 0s - loss: 0.5894 - acc: 0.8987
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5901 - acc: 0.8972
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5899 - acc: 0.8974
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5899 - acc: 0.8963
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5901 - acc: 0.8952
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5897 - acc: 0.8960
4800/4800 [==============================] - 3s 544us/step - loss: 0.5892 - acc: 0.8960 - val_loss: 0.3896 - val_acc: 0.8935
Epoch 18/20

 300/4800 [>.............................] - ETA: 1s - loss: 0.6023 - acc: 0.8573
 600/4800 [==>...........................] - ETA: 1s - loss: 0.5956 - acc: 0.8769
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5920 - acc: 0.8839
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5900 - acc: 0.8874
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5901 - acc: 0.8871
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5891 - acc: 0.8898
2100/4800 [============>.................] - ETA: 1s - loss: 0.5896 - acc: 0.8874
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5892 - acc: 0.8903
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5886 - acc: 0.8935
3000/4800 [=================>............] - ETA: 0s - loss: 0.5884 - acc: 0.8943
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5886 - acc: 0.8942
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5881 - acc: 0.8956
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5883 - acc: 0.8963
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5880 - acc: 0.8978
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5890 - acc: 0.8954
4800/4800 [==============================] - 3s 535us/step - loss: 0.5889 - acc: 0.8961 - val_loss: 0.3788 - val_acc: 0.8942
Epoch 19/20

 300/4800 [>.............................] - ETA: 1s - loss: 0.5732 - acc: 0.8980
 600/4800 [==>...........................] - ETA: 1s - loss: 0.5806 - acc: 0.8951
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5875 - acc: 0.8855
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5875 - acc: 0.8887
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5880 - acc: 0.8865
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5878 - acc: 0.8863
2100/4800 [============>.................] - ETA: 1s - loss: 0.5882 - acc: 0.8892
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5869 - acc: 0.8902
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5873 - acc: 0.8927
3000/4800 [=================>............] - ETA: 0s - loss: 0.5880 - acc: 0.8922
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5886 - acc: 0.8907
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5890 - acc: 0.8913
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5892 - acc: 0.8920
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5889 - acc: 0.8946
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5884 - acc: 0.8967
4800/4800 [==============================] - 3s 550us/step - loss: 0.5881 - acc: 0.8982 - val_loss: 0.3820 - val_acc: 0.9446
Epoch 20/20

 300/4800 [>.............................] - ETA: 1s - loss: 0.5740 - acc: 0.9082
 600/4800 [==>...........................] - ETA: 1s - loss: 0.5787 - acc: 0.9125
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5807 - acc: 0.9154
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5808 - acc: 0.9161
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5835 - acc: 0.9124
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5831 - acc: 0.9119
2100/4800 [============>.................] - ETA: 1s - loss: 0.5839 - acc: 0.9110
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5839 - acc: 0.9118
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5842 - acc: 0.9100
3000/4800 [=================>............] - ETA: 0s - loss: 0.5844 - acc: 0.9091
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5860 - acc: 0.9063
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5856 - acc: 0.9074
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5859 - acc: 0.9072
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5857 - acc: 0.9078
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5856 - acc: 0.9080
4800/4800 [==============================] - 3s 543us/step - loss: 0.5857 - acc: 0.9084 - val_loss: 0.3638 - val_acc: 0.9438
C:\Anaconda3\lib\site-packages\h5py\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
Finished
