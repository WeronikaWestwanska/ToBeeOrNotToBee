----------------------------------
- Parameters.py                  -
----------------------------------
data_params = {
    "width"                 : 640,
    "height"                : 480,
    "labelled_train_db"     : 'data/labels.train.db',
    "labelled_train_dir"    : 'data/labelled.train/',
    "labelled_validate_db"  : 'data/labels.validate.db',
    "labelled_validate_dir" : 'data/labelled.validate/',
    "segmented_dir"         : 'data/segmented/'
}

model_params = {
    "num_classes" : 2,
    "batch_size"  : 300,
    "epochs"      : 20
}

hyper_params = {
    "max_training_images_count"    : 100,     # if value is -1 then take all training images
    "max_testing_images_count"     : -1,      # if value is -1 then take all training images
    "l2_regularisation"            : 0.0005,
    "dropout"                      : 0.50,
    "learning_rate"                : 0.0001,
    "percentage_train"             : 80,
    "windows_per_image_on_average" : 60,
    "window_size"                  : 40,
    "bee_radius"                   : 20,
    "min_bee_prob"                 : 0.80,
    "max_bee_prob"                 : 1.00,
    "min_bee_prct_window"          : 45.0,
    "bee_window_percentage"        : 20,
    "filters_count"                : 32,
    "kernel_size"                  : 3,
    "padding_to_remove"            : 4,
    "sliding_window_step"          : 2
}
----------------------------------
- Training                       -
----------------------------------
Data Parameters:
Key: width, Value: 640
Key: height, Value: 480
Key: labelled_train_db, Value: data/labels.train.db
Key: labelled_train_dir, Value: data/labelled.train/
Key: labelled_validate_db, Value: data/labels.validate.db
Key: labelled_validate_dir, Value: data/labelled.validate/
Key: segmented_dir, Value: data/segmented/
Model Parameters:
Key: num_classes, Value: 2
Key: batch_size, Value: 300
Key: epochs, Value: 20
Hyper Parameters:
Key: max_training_images_count, Value: 100
Key: max_testing_images_count, Value: -1
Key: l2_regularisation, Value: 0.0005
Key: dropout, Value: 0.5
Key: learning_rate, Value: 0.0001
Key: percentage_train, Value: 80
Key: windows_per_image_on_average, Value: 60
Key: window_size, Value: 40
Key: bee_radius, Value: 20
Key: min_bee_prob, Value: 0.8
Key: max_bee_prob, Value: 1.0
Key: min_bee_prct_window, Value: 45.0
Key: bee_window_percentage, Value: 20
Key: filters_count, Value: 32
Key: kernel_size, Value: 3
Key: padding_to_remove, Value: 4
Key: sliding_window_step, Value: 2
Index is 5
Index is 75
Index is 12
Index is 34
Index is 96
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 40, 40, 3)    0                                            
__________________________________________________________________________________________________
conv1_1 (Conv2D)                (None, 40, 40, 32)   896         input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 40, 40, 32)   9248        conv1_1[0][0]                    
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 20, 20, 32)   0           conv2d_1[0][0]                   
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 20, 20, 64)   18496       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 20, 20, 64)   36928       conv2d_2[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 10, 10, 64)   0           conv2d_3[0][0]                   
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 10, 10, 128)  73856       max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 10, 10, 128)  147584      conv2d_4[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 128)    0           conv2d_5[0][0]                   
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 5, 5, 256)    295168      max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 5, 5, 256)    590080      conv2d_6[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)  (None, 2, 2, 256)    0           conv2d_7[0][0]                   
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 2, 2, 512)    1180160     max_pooling2d_4[0][0]            
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 2, 2, 512)    2359808     conv2d_8[0][0]                   
__________________________________________________________________________________________________
up_sampling2d_1 (UpSampling2D)  (None, 4, 4, 512)    0           conv2d_9[0][0]                   
__________________________________________________________________________________________________
cropping2d_1 (Cropping2D)       (None, 4, 4, 256)    0           conv2d_7[0][0]                   
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 4, 4, 768)    0           up_sampling2d_1[0][0]            
                                                                 cropping2d_1[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 4, 4, 256)    1769728     concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 4, 4, 256)    590080      conv2d_10[0][0]                  
__________________________________________________________________________________________________
up_sampling2d_2 (UpSampling2D)  (None, 8, 8, 256)    0           conv2d_11[0][0]                  
__________________________________________________________________________________________________
cropping2d_2 (Cropping2D)       (None, 8, 8, 128)    0           conv2d_5[0][0]                   
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 8, 8, 384)    0           up_sampling2d_2[0][0]            
                                                                 cropping2d_2[0][0]               
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 8, 8, 128)    442496      concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 8, 8, 128)    147584      conv2d_12[0][0]                  
__________________________________________________________________________________________________
up_sampling2d_3 (UpSampling2D)  (None, 16, 16, 128)  0           conv2d_13[0][0]                  
__________________________________________________________________________________________________
cropping2d_3 (Cropping2D)       (None, 16, 16, 64)   0           conv2d_3[0][0]                   
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 16, 16, 192)  0           up_sampling2d_3[0][0]            
                                                                 cropping2d_3[0][0]               
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 16, 16, 64)   110656      concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 16, 16, 64)   36928       conv2d_14[0][0]                  
__________________________________________________________________________________________________
up_sampling2d_4 (UpSampling2D)  (None, 32, 32, 64)   0           conv2d_15[0][0]                  
__________________________________________________________________________________________________
cropping2d_4 (Cropping2D)       (None, 32, 32, 32)   0           conv2d_1[0][0]                   
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 32, 32, 96)   0           up_sampling2d_4[0][0]            2019-04-28 20:10:51.576780: I T:\src\github\tensorflow\tensorflow\core\platform\cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2019-04-28 20:10:51.880492: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1405] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.8095
pciBusID: 0000:65:00.0
totalMemory: 8.00GiB freeMemory: 6.59GiB
2019-04-28 20:10:51.881794: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1484] Adding visible gpu devices: 0
2019-04-28 20:10:52.661879: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-04-28 20:10:52.662659: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:971]      0 
2019-04-28 20:10:52.663168: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:984] 0:   N 
2019-04-28 20:10:52.663818: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6360 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:65:00.0, compute capability: 6.1)

                                                                 cropping2d_4[0][0]               
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 32, 32, 32)   27680       concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 32, 32, 32)   9248        conv2d_16[0][0]                  
__________________________________________________________________________________________________
zero_padding2d_1 (ZeroPadding2D (None, 40, 40, 32)   0           conv2d_17[0][0]                  
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 40, 40, 2)    66          zero_padding2d_1[0][0]           
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 40, 40, 2)    0           conv2d_18[0][0]                  
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 40, 40, 2)    0           activation_1[0][0]               
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 40, 40, 2)    0           dropout_1[0][0]                  
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 40, 40, 2)    0           activation_2[0][0]               
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 40, 2)    0           dropout_2[0][0]                  
==================================================================================================
Total params: 7,846,690
Trainable params: 7,846,690
Non-trainable params: 0
__________________________________________________________________________________________________
Analysing training image 0 out of 100 images
Analysing training image 1 out of 100 images
Analysing training image 2 out of 100 images
Analysing training image 3 out of 100 images
Analysing training image 4 out of 100 images
Analysing training image 5 out of 100 images
Analysing training image 6 out of 100 images
Analysing training image 7 out of 100 images
Analysing training image 8 out of 100 images
Analysing training image 9 out of 100 images
Analysing training image 10 out of 100 images
Analysing training image 11 out of 100 images
Analysing training image 12 out of 100 images
Analysing training image 13 out of 100 images
Analysing training image 14 out of 100 images
Analysing training image 15 out of 100 images
Analysing training image 16 out of 100 images
Analysing training image 17 out of 100 images
Analysing training image 18 out of 100 images
Analysing training image 19 out of 100 images
Analysing training image 20 out of 100 images
Analysing training image 21 out of 100 images
Analysing training image 22 out of 100 images
Analysing training image 23 out of 100 images
Analysing training image 24 out of 100 images
Analysing training image 25 out of 100 images
Analysing training image 26 out of 100 images
Analysing training image 27 out of 100 images
Analysing training image 28 out of 100 images
Analysing training image 29 out of 100 images
Analysing training image 30 out of 100 images
Analysing training image 31 out of 100 images
Analysing training image 32 out of 100 images
Analysing training image 33 out of 100 images
Analysing training image 34 out of 100 images
Analysing training image 35 out of 100 images
Analysing training image 36 out of 100 images
Analysing training image 37 out of 100 images
Analysing training image 38 out of 100 images
Analysing training image 39 out of 100 images
Analysing training image 40 out of 100 images
Analysing training image 41 out of 100 images
Analysing training image 42 out of 100 images
Analysing training image 43 out of 100 images
Analysing training image 44 out of 100 images
Analysing training image 45 out of 100 images
Analysing training image 46 out of 100 images
Analysing training image 47 out of 100 images
Analysing training image 48 out of 100 images
Analysing training image 49 out of 100 images
Analysing training image 50 out of 100 images
Analysing training image 51 out of 100 images
Analysing training image 52 out of 100 images
Analysing training image 53 out of 100 images
Analysing training image 54 out of 100 images
Analysing training image 55 out of 100 images
Analysing training image 56 out of 100 images
Analysing training image 57 out of 100 images
Analysing training image 58 out of 100 images
Analysing training image 59 out of 100 images
Analysing training image 60 out of 100 images
Analysing training image 61 out of 100 images
Analysing training image 62 out of 100 images
Analysing training image 63 out of 100 images
Analysing training image 64 out of 100 images
Analysing training image 65 out of 100 images
Analysing training image 66 out of 100 images
Analysing training image 67 out of 100 images
Analysing training image 68 out of 100 images
Analysing training image 69 out of 100 images
Analysing training image 70 out of 100 images
Analysing training image 71 out of 100 images
Analysing training image 72 out of 100 images
Analysing training image 73 out of 100 images
Analysing training image 74 out of 100 images
Analysing training image 75 out of 100 images
Analysing training image 76 out of 100 images
Analysing training image 77 out of 100 images
Analysing training image 78 out of 100 images
Analysing training image 79 out of 100 images
Analysing training image 80 out of 100 images
Analysing training image 81 out of 100 images
Analysing training image 82 out of 100 images
Analysing training image 83 out of 100 images
Analysing training image 84 out of 100 images
Analysing training image 85 out of 100 images
Analysing training image 86 out of 100 images
Analysing training image 87 out of 100 images
Analysing training image 88 out of 100 images
Analysing training image 89 out of 100 images
Analysing training image 90 out of 100 images
Analysing training image 91 out of 100 images
Analysing training image 92 out of 100 images
Analysing training image 93 out of 100 images
Analysing training image 94 out of 100 images
Analysing training image 95 out of 100 images
Analysing training image 96 out of 100 images
Analysing training image 97 out of 100 images
Analysing training image 98 out of 100 images
Analysing training image 99 out of 100 images
Train on 4800 samples, validate on 1200 samples
Epoch 1/20

 300/4800 [>.............................] - ETA: 1:26 - loss: 0.6900 - acc: 0.7753
 600/4800 [==>...........................] - ETA: 41s - loss: 0.6932 - acc: 0.7705 
 900/4800 [====>.........................] - ETA: 26s - loss: 0.6909 - acc: 0.7756
1200/4800 [======>.......................] - ETA: 18s - loss: 0.6874 - acc: 0.7795
1500/4800 [========>.....................] - ETA: 14s - loss: 0.6830 - acc: 0.7867
1800/4800 [==========>...................] - ETA: 10s - loss: 0.6805 - acc: 0.8010
2100/4800 [============>.................] - ETA: 8s - loss: 0.6788 - acc: 0.8153 
2400/4800 [==============>...............] - ETA: 6s - loss: 0.6772 - acc: 0.8259
2700/4800 [===============>..............] - ETA: 5s - loss: 0.6751 - acc: 0.8347
3000/4800 [=================>............] - ETA: 4s - loss: 0.6739 - acc: 0.8394
3300/4800 [===================>..........] - ETA: 3s - loss: 0.6726 - acc: 0.8430
3600/4800 [=====================>........] - ETA: 2s - loss: 0.6704 - acc: 0.8472
3900/4800 [=======================>......] - ETA: 1s - loss: 0.6675 - acc: 0.8505
4200/4800 [=========================>....] - ETA: 1s - loss: 0.6652 - acc: 0.8532
4500/4800 [===========================>..] - ETA: 0s - loss: 0.6634 - acc: 0.8553
4800/4800 [==============================] - 8s 2ms/step - loss: 0.6613 - acc: 0.8585 - val_loss: 0.5422 - val_acc: 0.8995
Epoch 2/20

 300/4800 [>.............................] - ETA: 1s - loss: 0.6482 - acc: 0.8750
 600/4800 [==>...........................] - ETA: 1s - loss: 0.6424 - acc: 0.8795
 900/4800 [====>.........................] - ETA: 1s - loss: 0.6406 - acc: 0.8830
1200/4800 [======>.......................] - ETA: 1s - loss: 0.6332 - acc: 0.8915
1500/4800 [========>.....................] - ETA: 1s - loss: 0.6306 - acc: 0.8953
1800/4800 [==========>...................] - ETA: 1s - loss: 0.6309 - acc: 0.8949
2100/4800 [============>.................] - ETA: 1s - loss: 0.6314 - acc: 0.8952
2400/4800 [==============>...............] - ETA: 1s - loss: 0.6310 - acc: 0.8919
2700/4800 [===============>..............] - ETA: 1s - loss: 0.6321 - acc: 0.8894
3000/4800 [=================>............] - ETA: 0s - loss: 0.6309 - acc: 0.8922
3300/4800 [===================>..........] - ETA: 0s - loss: 0.6299 - acc: 0.8939
3600/4800 [=====================>........] - ETA: 0s - loss: 0.6299 - acc: 0.8927
3900/4800 [=======================>......] - ETA: 0s - loss: 0.6294 - acc: 0.8939
4200/4800 [=========================>....] - ETA: 0s - loss: 0.6290 - acc: 0.8935
4500/4800 [===========================>..] - ETA: 0s - loss: 0.6283 - acc: 0.8945
4800/4800 [==============================] - 3s 549us/step - loss: 0.6279 - acc: 0.8943 - val_loss: 0.5478 - val_acc: 0.8995
Epoch 3/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.6336 - acc: 0.8826
 600/4800 [==>...........................] - ETA: 2s - loss: 0.6255 - acc: 0.8968
 900/4800 [====>.........................] - ETA: 1s - loss: 0.6243 - acc: 0.9016
1200/4800 [======>.......................] - ETA: 1s - loss: 0.6231 - acc: 0.9022
1500/4800 [========>.....................] - ETA: 1s - loss: 0.6224 - acc: 0.9051
1800/4800 [==========>...................] - ETA: 1s - loss: 0.6228 - acc: 0.9017
2100/4800 [============>.................] - ETA: 1s - loss: 0.6203 - acc: 0.9031
2400/4800 [==============>...............] - ETA: 1s - loss: 0.6213 - acc: 0.9009
2700/4800 [===============>..............] - ETA: 1s - loss: 0.6225 - acc: 0.8987
3000/4800 [=================>............] - ETA: 0s - loss: 0.6219 - acc: 0.8980
3300/4800 [===================>..........] - ETA: 0s - loss: 0.6229 - acc: 0.8959
3600/4800 [=====================>........] - ETA: 0s - loss: 0.6228 - acc: 0.8948
3900/4800 [=======================>......] - ETA: 0s - loss: 0.6229 - acc: 0.8941
4200/4800 [=========================>....] - ETA: 0s - loss: 0.6220 - acc: 0.8948
4500/4800 [===========================>..] - ETA: 0s - loss: 0.6216 - acc: 0.8952
4800/4800 [==============================] - 3s 545us/step - loss: 0.6217 - acc: 0.8943 - val_loss: 0.5477 - val_acc: 0.8995
Epoch 4/20

 300/4800 [>.............................] - ETA: 1s - loss: 0.6251 - acc: 0.8996
 600/4800 [==>...........................] - ETA: 1s - loss: 0.6221 - acc: 0.8951
 900/4800 [====>.........................] - ETA: 1s - loss: 0.6218 - acc: 0.8941
1200/4800 [======>.......................] - ETA: 1s - loss: 0.6200 - acc: 0.8961
1500/4800 [========>.....................] - ETA: 1s - loss: 0.6188 - acc: 0.8986
1800/4800 [==========>...................] - ETA: 1s - loss: 0.6184 - acc: 0.8970
2100/4800 [============>.................] - ETA: 1s - loss: 0.6191 - acc: 0.8954
2400/4800 [==============>...............] - ETA: 1s - loss: 0.6193 - acc: 0.8937
2700/4800 [===============>..............] - ETA: 1s - loss: 0.6190 - acc: 0.8949
3000/4800 [=================>............] - ETA: 0s - loss: 0.6184 - acc: 0.8936
3300/4800 [===================>..........] - ETA: 0s - loss: 0.6188 - acc: 0.8944
3600/4800 [=====================>........] - ETA: 0s - loss: 0.6184 - acc: 0.8943
3900/4800 [=======================>......] - ETA: 0s - loss: 0.6189 - acc: 0.8943
4200/4800 [=========================>....] - ETA: 0s - loss: 0.6185 - acc: 0.8941
4500/4800 [===========================>..] - ETA: 0s - loss: 0.6185 - acc: 0.8944
4800/4800 [==============================] - 3s 541us/step - loss: 0.6185 - acc: 0.8943 - val_loss: 0.5444 - val_acc: 0.8995
Epoch 5/20

 300/4800 [>.............................] - ETA: 1s - loss: 0.6113 - acc: 0.9080
 600/4800 [==>...........................] - ETA: 1s - loss: 0.6105 - acc: 0.9064
 900/4800 [====>.........................] - ETA: 1s - loss: 0.6147 - acc: 0.8955
1200/4800 [======>.......................] - ETA: 1s - loss: 0.6146 - acc: 0.8958
1500/4800 [========>.....................] - ETA: 1s - loss: 0.6148 - acc: 0.8988
1800/4800 [==========>...................] - ETA: 1s - loss: 0.6150 - acc: 0.8961
2100/4800 [============>.................] - ETA: 1s - loss: 0.6134 - acc: 0.8965
2400/4800 [==============>...............] - ETA: 1s - loss: 0.6140 - acc: 0.8948
2700/4800 [===============>..............] - ETA: 1s - loss: 0.6137 - acc: 0.8934
3000/4800 [=================>............] - ETA: 0s - loss: 0.6140 - acc: 0.8919
3300/4800 [===================>..........] - ETA: 0s - loss: 0.6141 - acc: 0.8925
3600/4800 [=====================>........] - ETA: 0s - loss: 0.6136 - acc: 0.8938
3900/4800 [=======================>......] - ETA: 0s - loss: 0.6129 - acc: 0.8939
4200/4800 [=========================>....] - ETA: 0s - loss: 0.6129 - acc: 0.8946
4500/4800 [===========================>..] - ETA: 0s - loss: 0.6130 - acc: 0.8944
4800/4800 [==============================] - 3s 539us/step - loss: 0.6126 - acc: 0.8947 - val_loss: 0.4896 - val_acc: 0.9113
Epoch 6/20

 300/4800 [>.............................] - ETA: 1s - loss: 0.6044 - acc: 0.9069
 600/4800 [==>...........................] - ETA: 1s - loss: 0.6040 - acc: 0.8923
 900/4800 [====>.........................] - ETA: 1s - loss: 0.6044 - acc: 0.8971
1200/4800 [======>.......................] - ETA: 1s - loss: 0.6032 - acc: 0.8958
1500/4800 [========>.....................] - ETA: 1s - loss: 0.6035 - acc: 0.8977
1800/4800 [==========>...................] - ETA: 1s - loss: 0.6026 - acc: 0.9006
2100/4800 [============>.................] - ETA: 1s - loss: 0.6026 - acc: 0.8999
2400/4800 [==============>...............] - ETA: 1s - loss: 0.6027 - acc: 0.8996
2700/4800 [===============>..............] - ETA: 1s - loss: 0.6031 - acc: 0.8982
3000/4800 [=================>............] - ETA: 0s - loss: 0.6042 - acc: 0.8958
3300/4800 [===================>..........] - ETA: 0s - loss: 0.6044 - acc: 0.8964
3600/4800 [=====================>........] - ETA: 0s - loss: 0.6043 - acc: 0.8960
3900/4800 [=======================>......] - ETA: 0s - loss: 0.6036 - acc: 0.8977
4200/4800 [=========================>....] - ETA: 0s - loss: 0.6031 - acc: 0.8984
4500/4800 [===========================>..] - ETA: 0s - loss: 0.6022 - acc: 0.8990
4800/4800 [==============================] - 3s 534us/step - loss: 0.6028 - acc: 0.8985 - val_loss: 0.4312 - val_acc: 0.9125
Epoch 7/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.6160 - acc: 0.8863
 600/4800 [==>...........................] - ETA: 2s - loss: 0.6091 - acc: 0.8874
 900/4800 [====>.........................] - ETA: 1s - loss: 0.6070 - acc: 0.8850
1200/4800 [======>.......................] - ETA: 1s - loss: 0.6025 - acc: 0.8906
1500/4800 [========>.....................] - ETA: 1s - loss: 0.6018 - acc: 0.8937
1800/4800 [==========>...................] - ETA: 1s - loss: 0.6003 - acc: 0.8972
2100/4800 [============>.................] - ETA: 1s - loss: 0.6003 - acc: 0.8961
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5986 - acc: 0.8992
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5994 - acc: 0.8981
3000/4800 [=================>............] - ETA: 0s - loss: 0.5991 - acc: 0.8989
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5982 - acc: 0.9009
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5982 - acc: 0.9001
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5979 - acc: 0.9003
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5976 - acc: 0.9016
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5983 - acc: 0.9004
4800/4800 [==============================] - 3s 547us/step - loss: 0.5981 - acc: 0.9006 - val_loss: 0.4591 - val_acc: 0.9243
Epoch 8/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5916 - acc: 0.9019
 600/4800 [==>...........................] - ETA: 2s - loss: 0.5965 - acc: 0.8954
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5966 - acc: 0.8934
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5969 - acc: 0.8944
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5956 - acc: 0.8998
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5963 - acc: 0.8987
2100/4800 [============>.................] - ETA: 1s - loss: 0.5965 - acc: 0.8983
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5964 - acc: 0.8991
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5959 - acc: 0.8989
3000/4800 [=================>............] - ETA: 0s - loss: 0.5960 - acc: 0.9000
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5962 - acc: 0.9011
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5959 - acc: 0.9016
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5952 - acc: 0.9015
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5951 - acc: 0.9016
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5950 - acc: 0.9019
4800/4800 [==============================] - 3s 548us/step - loss: 0.5950 - acc: 0.9016 - val_loss: 0.3924 - val_acc: 0.9235
Epoch 9/20

 300/4800 [>.............................] - ETA: 1s - loss: 0.5931 - acc: 0.9102
 600/4800 [==>...........................] - ETA: 1s - loss: 0.5937 - acc: 0.9027
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5922 - acc: 0.9055
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5901 - acc: 0.9100
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5922 - acc: 0.9036
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5931 - acc: 0.9038
2100/4800 [============>.................] - ETA: 1s - loss: 0.5935 - acc: 0.9027
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5943 - acc: 0.9001
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5940 - acc: 0.8972
3000/4800 [=================>............] - ETA: 0s - loss: 0.5930 - acc: 0.8990
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5932 - acc: 0.8984
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5933 - acc: 0.8983
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5935 - acc: 0.8997
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5930 - acc: 0.9011
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5931 - acc: 0.9020
4800/4800 [==============================] - 3s 547us/step - loss: 0.5929 - acc: 0.9027 - val_loss: 0.3934 - val_acc: 0.9300
Epoch 10/20

 300/4800 [>.............................] - ETA: 1s - loss: 0.5901 - acc: 0.9044
 600/4800 [==>...........................] - ETA: 1s - loss: 0.5958 - acc: 0.9027
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5974 - acc: 0.8979
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5969 - acc: 0.8958
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5939 - acc: 0.9025
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5917 - acc: 0.9034
2100/4800 [============>.................] - ETA: 1s - loss: 0.5927 - acc: 0.9021
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5929 - acc: 0.9020
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5923 - acc: 0.9031
3000/4800 [=================>............] - ETA: 0s - loss: 0.5926 - acc: 0.9029
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5927 - acc: 0.9023
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5918 - acc: 0.9029
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5916 - acc: 0.9026
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5918 - acc: 0.9037
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5921 - acc: 0.9042
4800/4800 [==============================] - 3s 541us/step - loss: 0.5915 - acc: 0.9049 - val_loss: 0.4201 - val_acc: 0.9426
Epoch 11/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5827 - acc: 0.9222
 600/4800 [==>...........................] - ETA: 1s - loss: 0.5880 - acc: 0.9138
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5886 - acc: 0.9137
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5911 - acc: 0.9105
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5894 - acc: 0.9080
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5889 - acc: 0.9106
2100/4800 [============>.................] - ETA: 1s - loss: 0.5906 - acc: 0.9075
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5905 - acc: 0.9060
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5903 - acc: 0.9086
3000/4800 [=================>............] - ETA: 0s - loss: 0.5895 - acc: 0.9099
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5891 - acc: 0.9094
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5895 - acc: 0.9086
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5897 - acc: 0.9081
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5902 - acc: 0.9065
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5902 - acc: 0.9063
4800/4800 [==============================] - 3s 552us/step - loss: 0.5902 - acc: 0.9062 - val_loss: 0.3813 - val_acc: 0.9434
Epoch 12/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5866 - acc: 0.9104
 600/4800 [==>...........................] - ETA: 2s - loss: 0.5884 - acc: 0.9050
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5907 - acc: 0.9024
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5899 - acc: 0.9004
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5906 - acc: 0.9008
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5896 - acc: 0.9017
2100/4800 [============>.................] - ETA: 1s - loss: 0.5886 - acc: 0.9051
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5886 - acc: 0.9072
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5882 - acc: 0.9077
3000/4800 [=================>............] - ETA: 0s - loss: 0.5882 - acc: 0.9083
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5885 - acc: 0.9079
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5889 - acc: 0.9077
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5888 - acc: 0.9070
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5891 - acc: 0.9067
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5891 - acc: 0.9074
4800/4800 [==============================] - 3s 550us/step - loss: 0.5896 - acc: 0.9065 - val_loss: 0.3856 - val_acc: 0.9452
Epoch 13/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5863 - acc: 0.9230
 600/4800 [==>...........................] - ETA: 1s - loss: 0.5903 - acc: 0.9091
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5890 - acc: 0.9139
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5902 - acc: 0.9164
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5914 - acc: 0.9132
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5909 - acc: 0.9117
2100/4800 [============>.................] - ETA: 1s - loss: 0.5909 - acc: 0.9091
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5903 - acc: 0.9103
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5902 - acc: 0.9091
3000/4800 [=================>............] - ETA: 0s - loss: 0.5905 - acc: 0.9082
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5898 - acc: 0.9098
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5892 - acc: 0.9090
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5891 - acc: 0.9084
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5889 - acc: 0.9062
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5893 - acc: 0.9062
4800/4800 [==============================] - 3s 537us/step - loss: 0.5890 - acc: 0.9068 - val_loss: 0.4179 - val_acc: 0.9456
Epoch 14/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5911 - acc: 0.9113
 600/4800 [==>...........................] - ETA: 2s - loss: 0.5885 - acc: 0.9133
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5899 - acc: 0.9086
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5893 - acc: 0.9070
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5899 - acc: 0.9061
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5895 - acc: 0.9065
2100/4800 [============>.................] - ETA: 1s - loss: 0.5902 - acc: 0.9063
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5903 - acc: 0.9055
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5896 - acc: 0.9047
3000/4800 [=================>............] - ETA: 0s - loss: 0.5895 - acc: 0.9056
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5885 - acc: 0.9069
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5878 - acc: 0.9078
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5876 - acc: 0.9082
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5878 - acc: 0.9078
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5877 - acc: 0.9081
4800/4800 [==============================] - 3s 542us/step - loss: 0.5879 - acc: 0.9073 - val_loss: 0.3752 - val_acc: 0.9464
Epoch 15/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5822 - acc: 0.9120
 600/4800 [==>...........................] - ETA: 1s - loss: 0.5898 - acc: 0.8936
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5890 - acc: 0.9029
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5896 - acc: 0.9044
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5899 - acc: 0.9036
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5892 - acc: 0.9039
2100/4800 [============>.................] - ETA: 1s - loss: 0.5891 - acc: 0.9049
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5886 - acc: 0.9071
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5884 - acc: 0.9094
3000/4800 [=================>............] - ETA: 0s - loss: 0.5886 - acc: 0.9094
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5880 - acc: 0.9083
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5881 - acc: 0.9079
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5875 - acc: 0.9068
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5875 - acc: 0.9067
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5870 - acc: 0.9064
4800/4800 [==============================] - 3s 539us/step - loss: 0.5875 - acc: 0.9073 - val_loss: 0.4041 - val_acc: 0.9485
Epoch 16/20

 300/4800 [>.............................] - ETA: 1s - loss: 0.5833 - acc: 0.9121
 600/4800 [==>...........................] - ETA: 1s - loss: 0.5851 - acc: 0.9119
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5862 - acc: 0.9146
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5873 - acc: 0.9162
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5870 - acc: 0.9134
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5878 - acc: 0.9084
2100/4800 [============>.................] - ETA: 1s - loss: 0.5879 - acc: 0.9084
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5870 - acc: 0.9095
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5865 - acc: 0.9104
3000/4800 [=================>............] - ETA: 0s - loss: 0.5867 - acc: 0.9103
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5868 - acc: 0.9097
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5872 - acc: 0.9073
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5869 - acc: 0.9075
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5869 - acc: 0.9078
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5867 - acc: 0.9075
4800/4800 [==============================] - 3s 550us/step - loss: 0.5870 - acc: 0.9076 - val_loss: 0.4168 - val_acc: 0.9473
Epoch 17/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5832 - acc: 0.9032
 600/4800 [==>...........................] - ETA: 1s - loss: 0.5819 - acc: 0.9015
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5824 - acc: 0.9043
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5846 - acc: 0.9064
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5852 - acc: 0.9073
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5856 - acc: 0.9059
2100/4800 [============>.................] - ETA: 1s - loss: 0.5862 - acc: 0.9063
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5867 - acc: 0.9080
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5876 - acc: 0.9068
3000/4800 [=================>............] - ETA: 0s - loss: 0.5880 - acc: 0.9056
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5878 - acc: 0.9068
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5877 - acc: 0.9077
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5870 - acc: 0.9077
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5868 - acc: 0.9075
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5871 - acc: 0.9079
4800/4800 [==============================] - 3s 546us/step - loss: 0.5870 - acc: 0.9075 - val_loss: 0.4013 - val_acc: 0.9454
Epoch 18/20

 300/4800 [>.............................] - ETA: 1s - loss: 0.5944 - acc: 0.9027
 600/4800 [==>...........................] - ETA: 1s - loss: 0.5913 - acc: 0.9086
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5904 - acc: 0.9104
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5886 - acc: 0.9082
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5879 - acc: 0.9126
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5884 - acc: 0.9102
2100/4800 [============>.................] - ETA: 1s - loss: 0.5872 - acc: 0.9121
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5874 - acc: 0.9115
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5876 - acc: 0.9089
3000/4800 [=================>............] - ETA: 0s - loss: 0.5870 - acc: 0.9100
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5872 - acc: 0.9074
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5864 - acc: 0.9081
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5862 - acc: 0.9079
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5863 - acc: 0.9069
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5860 - acc: 0.9084
4800/4800 [==============================] - 3s 540us/step - loss: 0.5866 - acc: 0.9077 - val_loss: 0.3909 - val_acc: 0.9490
Epoch 19/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5821 - acc: 0.9127
 600/4800 [==>...........................] - ETA: 2s - loss: 0.5812 - acc: 0.9169
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5810 - acc: 0.9163
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5819 - acc: 0.9136
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5824 - acc: 0.9127
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5834 - acc: 0.9130
2100/4800 [============>.................] - ETA: 1s - loss: 0.5838 - acc: 0.9129
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5843 - acc: 0.9113
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5844 - acc: 0.9094
3000/4800 [=================>............] - ETA: 0s - loss: 0.5850 - acc: 0.9085
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5850 - acc: 0.9079
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5855 - acc: 0.9079
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5857 - acc: 0.9062
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5856 - acc: 0.9065
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5856 - acc: 0.9079
4800/4800 [==============================] - 3s 541us/step - loss: 0.5857 - acc: 0.9079 - val_loss: 0.3973 - val_acc: 0.9502
Epoch 20/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5883 - acc: 0.9014
 600/4800 [==>...........................] - ETA: 2s - loss: 0.5871 - acc: 0.9002
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5881 - acc: 0.8991
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5868 - acc: 0.9048
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5870 - acc: 0.9017
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5867 - acc: 0.9056
2100/4800 [============>.................] - ETA: 1s - loss: 0.5866 - acc: 0.9062
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5861 - acc: 0.9073
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5858 - acc: 0.9085
3000/4800 [=================>............] - ETA: 0s - loss: 0.5847 - acc: 0.9076
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5854 - acc: 0.9079
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5849 - acc: 0.9069
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5851 - acc: 0.9086
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5853 - acc: 0.9084
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5849 - acc: 0.9084
4800/4800 [==============================] - 3s 546us/step - loss: 0.5850 - acc: 0.9084 - val_loss: 0.3728 - val_acc: 0.9513
C:\Anaconda3\lib\site-packages\h5py\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
Finished
