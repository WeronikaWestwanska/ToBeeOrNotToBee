----------------------------------
- Parameters.py                  -
----------------------------------
data_params = {
    "width"                 : 640,
    "height"                : 480,
    "labelled_train_db"     : 'data/labels.train.db',
    "labelled_train_dir"    : 'data/labelled.train/',
    "labelled_validate_db"  : 'data/labels.validate.db',
    "labelled_validate_dir" : 'data/labelled.validate/',
    "segmented_dir"         : 'data/segmented/'
}

model_params = {
    "num_classes" : 2,
    "batch_size"  : 300,
    "epochs"      : 20
}

hyper_params = {
    "max_training_images_count"    : 100,     # if value is -1 then take all training images
    "max_testing_images_count"     : -1,      # if value is -1 then take all training images
    "l2_regularisation"            : 0.0005,
    "dropout"                      : 0.50,
    "learning_rate"                : 0.0001,
    "percentage_train"             : 80,
    "windows_per_image_on_average" : 60,
    "window_size"                  : 40,
    "bee_radius"                   : 20,
    "min_bee_prob"                 : 0.80,
    "max_bee_prob"                 : 1.00,
    "min_bee_prct_window"          : 45.0,
    "bee_window_percentage"        : 20,
    "filters_count"                : 32,
    "kernel_size"                  : 3,
    "padding_to_remove"            : 4,
    "sliding_window_step"          : 2
}
----------------------------------
- Training                       -
----------------------------------
Data Parameters:
Key: width, Value: 640
Key: height, Value: 480
Key: labelled_train_db, Value: data/labels.train.db
Key: labelled_train_dir, Value: data/labelled.train/
Key: labelled_validate_db, Value: data/labels.validate.db
Key: labelled_validate_dir, Value: data/labelled.validate/
Key: segmented_dir, Value: data/segmented/
Model Parameters:
Key: num_classes, Value: 2
Key: batch_size, Value: 300
Key: epochs, Value: 20
Hyper Parameters:
Key: max_training_images_count, Value: 100
Key: max_testing_images_count, Value: -1
Key: l2_regularisation, Value: 0.0005
Key: dropout, Value: 0.5
Key: learning_rate, Value: 0.0001
Key: percentage_train, Value: 80
Key: windows_per_image_on_average, Value: 60
Key: window_size, Value: 40
Key: bee_radius, Value: 20
Key: min_bee_prob, Value: 0.8
Key: max_bee_prob, Value: 1.0
Key: min_bee_prct_window, Value: 45.0
Key: bee_window_percentage, Value: 20
Key: filters_count, Value: 32
Key: kernel_size, Value: 3
Key: padding_to_remove, Value: 4
Key: sliding_window_step, Value: 2
Index is 17
Index is 80
Index is 99
Index is 91
Index is 58
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 40, 40, 3)    0                                            
__________________________________________________________________________________________________
conv1_1 (Conv2D)                (None, 40, 40, 32)   896         input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 40, 40, 32)   9248        conv1_1[0][0]                    
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 20, 20, 32)   0           conv2d_1[0][0]                   
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 20, 20, 64)   18496       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 20, 20, 64)   36928       conv2d_2[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 10, 10, 64)   0           conv2d_3[0][0]                   
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 10, 10, 128)  73856       max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 10, 10, 128)  147584      conv2d_4[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 128)    0           conv2d_5[0][0]                   
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 5, 5, 256)    295168      max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 5, 5, 256)    590080      conv2d_6[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)  (None, 2, 2, 256)    0           conv2d_7[0][0]                   
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 2, 2, 512)    1180160     max_pooling2d_4[0][0]            
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 2, 2, 512)    2359808     conv2d_8[0][0]                   
__________________________________________________________________________________________________
up_sampling2d_1 (UpSampling2D)  (None, 4, 4, 512)    0           conv2d_9[0][0]                   
__________________________________________________________________________________________________
cropping2d_1 (Cropping2D)       (None, 4, 4, 256)    0           conv2d_7[0][0]                   
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 4, 4, 768)    0           up_sampling2d_1[0][0]            
                                                                 cropping2d_1[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 4, 4, 256)    1769728     concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 4, 4, 256)    590080      conv2d_10[0][0]                  
__________________________________________________________________________________________________
up_sampling2d_2 (UpSampling2D)  (None, 8, 8, 256)    0           conv2d_11[0][0]                  
__________________________________________________________________________________________________
cropping2d_2 (Cropping2D)       (None, 8, 8, 128)    0           conv2d_5[0][0]                   
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 8, 8, 384)    0           up_sampling2d_2[0][0]            
                                                                 cropping2d_2[0][0]               
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 8, 8, 128)    442496      concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 8, 8, 128)    147584      conv2d_12[0][0]                  
__________________________________________________________________________________________________
up_sampling2d_3 (UpSampling2D)  (None, 16, 16, 128)  0           conv2d_13[0][0]                  
__________________________________________________________________________________________________
cropping2d_3 (Cropping2D)       (None, 16, 16, 64)   0           conv2d_3[0][0]                   
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 16, 16, 192)  0           up_sampling2d_3[0][0]            
                                                                 cropping2d_3[0][0]               
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 16, 16, 64)   110656      concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 16, 16, 64)   36928       conv2d_14[0][0]                  
__________________________________________________________________________________________________
up_sampling2d_4 (UpSampling2D)  (None, 32, 32, 64)   0           conv2d_15[0][0]                  
__________________________________________________________________________________________________
cropping2d_4 (Cropping2D)       (None, 32, 32, 32)   0           conv2d_1[0][0]                   
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 32, 32, 96)   0           up_sampling2d_4[0][0]            2019-04-28 20:08:09.378993: I T:\src\github\tensorflow\tensorflow\core\platform\cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2019-04-28 20:08:09.707080: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1405] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.8095
pciBusID: 0000:65:00.0
totalMemory: 8.00GiB freeMemory: 6.59GiB
2019-04-28 20:08:09.708369: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1484] Adding visible gpu devices: 0
2019-04-28 20:08:10.557302: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-04-28 20:08:10.558095: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:971]      0 
2019-04-28 20:08:10.558604: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:984] 0:   N 
2019-04-28 20:08:10.559256: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6360 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:65:00.0, compute capability: 6.1)

                                                                 cropping2d_4[0][0]               
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 32, 32, 32)   27680       concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 32, 32, 32)   9248        conv2d_16[0][0]                  
__________________________________________________________________________________________________
zero_padding2d_1 (ZeroPadding2D (None, 40, 40, 32)   0           conv2d_17[0][0]                  
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 40, 40, 2)    66          zero_padding2d_1[0][0]           
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 40, 40, 2)    0           conv2d_18[0][0]                  
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 40, 40, 2)    0           activation_1[0][0]               
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 40, 40, 2)    0           dropout_1[0][0]                  
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 40, 40, 2)    0           activation_2[0][0]               
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 40, 2)    0           dropout_2[0][0]                  
==================================================================================================
Total params: 7,846,690
Trainable params: 7,846,690
Non-trainable params: 0
__________________________________________________________________________________________________
Analysing training image 0 out of 100 images
Analysing training image 1 out of 100 images
Analysing training image 2 out of 100 images
Analysing training image 3 out of 100 images
Analysing training image 4 out of 100 images
Analysing training image 5 out of 100 images
Analysing training image 6 out of 100 images
Analysing training image 7 out of 100 images
Analysing training image 8 out of 100 images
Analysing training image 9 out of 100 images
Analysing training image 10 out of 100 images
Analysing training image 11 out of 100 images
Analysing training image 12 out of 100 images
Analysing training image 13 out of 100 images
Analysing training image 14 out of 100 images
Analysing training image 15 out of 100 images
Analysing training image 16 out of 100 images
Analysing training image 17 out of 100 images
Analysing training image 18 out of 100 images
Analysing training image 19 out of 100 images
Analysing training image 20 out of 100 images
Analysing training image 21 out of 100 images
Analysing training image 22 out of 100 images
Analysing training image 23 out of 100 images
Analysing training image 24 out of 100 images
Analysing training image 25 out of 100 images
Analysing training image 26 out of 100 images
Analysing training image 27 out of 100 images
Analysing training image 28 out of 100 images
Analysing training image 29 out of 100 images
Analysing training image 30 out of 100 images
Analysing training image 31 out of 100 images
Analysing training image 32 out of 100 images
Analysing training image 33 out of 100 images
Analysing training image 34 out of 100 images
Analysing training image 35 out of 100 images
Analysing training image 36 out of 100 images
Analysing training image 37 out of 100 images
Analysing training image 38 out of 100 images
Analysing training image 39 out of 100 images
Analysing training image 40 out of 100 images
Analysing training image 41 out of 100 images
Analysing training image 42 out of 100 images
Analysing training image 43 out of 100 images
Analysing training image 44 out of 100 images
Analysing training image 45 out of 100 images
Analysing training image 46 out of 100 images
Analysing training image 47 out of 100 images
Analysing training image 48 out of 100 images
Analysing training image 49 out of 100 images
Analysing training image 50 out of 100 images
Analysing training image 51 out of 100 images
Analysing training image 52 out of 100 images
Analysing training image 53 out of 100 images
Analysing training image 54 out of 100 images
Analysing training image 55 out of 100 images
Analysing training image 56 out of 100 images
Analysing training image 57 out of 100 images
Analysing training image 58 out of 100 images
Analysing training image 59 out of 100 images
Analysing training image 60 out of 100 images
Analysing training image 61 out of 100 images
Analysing training image 62 out of 100 images
Analysing training image 63 out of 100 images
Analysing training image 64 out of 100 images
Analysing training image 65 out of 100 images
Analysing training image 66 out of 100 images
Analysing training image 67 out of 100 images
Analysing training image 68 out of 100 images
Analysing training image 69 out of 100 images
Analysing training image 70 out of 100 images
Analysing training image 71 out of 100 images
Analysing training image 72 out of 100 images
Analysing training image 73 out of 100 images
Analysing training image 74 out of 100 images
Analysing training image 75 out of 100 images
Analysing training image 76 out of 100 images
Analysing training image 77 out of 100 images
Analysing training image 78 out of 100 images
Analysing training image 79 out of 100 images
Analysing training image 80 out of 100 images
Analysing training image 81 out of 100 images
Analysing training image 82 out of 100 images
Analysing training image 83 out of 100 images
Analysing training image 84 out of 100 images
Analysing training image 85 out of 100 images
Analysing training image 86 out of 100 images
Analysing training image 87 out of 100 images
Analysing training image 88 out of 100 images
Analysing training image 89 out of 100 images
Analysing training image 90 out of 100 images
Analysing training image 91 out of 100 images
Analysing training image 92 out of 100 images
Analysing training image 93 out of 100 images
Analysing training image 94 out of 100 images
Analysing training image 95 out of 100 images
Analysing training image 96 out of 100 images
Analysing training image 97 out of 100 images
Analysing training image 98 out of 100 images
Analysing training image 99 out of 100 images
Train on 4800 samples, validate on 1200 samples
Epoch 1/20

 300/4800 [>.............................] - ETA: 1:26 - loss: 0.6743 - acc: 0.8822
 600/4800 [==>...........................] - ETA: 41s - loss: 0.6748 - acc: 0.8932 
 900/4800 [====>.........................] - ETA: 26s - loss: 0.6704 - acc: 0.8899
1200/4800 [======>.......................] - ETA: 18s - loss: 0.6692 - acc: 0.8885
1500/4800 [========>.....................] - ETA: 14s - loss: 0.6669 - acc: 0.8883
1800/4800 [==========>...................] - ETA: 10s - loss: 0.6643 - acc: 0.8886
2100/4800 [============>.................] - ETA: 8s - loss: 0.6616 - acc: 0.8893 
2400/4800 [==============>...............] - ETA: 6s - loss: 0.6600 - acc: 0.8898
2700/4800 [===============>..............] - ETA: 5s - loss: 0.6576 - acc: 0.8899
3000/4800 [=================>............] - ETA: 4s - loss: 0.6562 - acc: 0.8902
3300/4800 [===================>..........] - ETA: 3s - loss: 0.6542 - acc: 0.8902
3600/4800 [=====================>........] - ETA: 2s - loss: 0.6523 - acc: 0.8910
3900/4800 [=======================>......] - ETA: 1s - loss: 0.6500 - acc: 0.8921
4200/4800 [=========================>....] - ETA: 1s - loss: 0.6486 - acc: 0.8916
4500/4800 [===========================>..] - ETA: 0s - loss: 0.6469 - acc: 0.8917
4800/4800 [==============================] - 8s 2ms/step - loss: 0.6451 - acc: 0.8926 - val_loss: 0.5483 - val_acc: 0.8943
Epoch 2/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.6353 - acc: 0.8970
 600/4800 [==>...........................] - ETA: 2s - loss: 0.6299 - acc: 0.8965
 900/4800 [====>.........................] - ETA: 1s - loss: 0.6275 - acc: 0.9015
1200/4800 [======>.......................] - ETA: 1s - loss: 0.6287 - acc: 0.8992
1500/4800 [========>.....................] - ETA: 1s - loss: 0.6264 - acc: 0.9012
1800/4800 [==========>...................] - ETA: 1s - loss: 0.6258 - acc: 0.9019
2100/4800 [============>.................] - ETA: 1s - loss: 0.6261 - acc: 0.9009
2400/4800 [==============>...............] - ETA: 1s - loss: 0.6251 - acc: 0.9017
2700/4800 [===============>..............] - ETA: 1s - loss: 0.6251 - acc: 0.8988
3000/4800 [=================>............] - ETA: 0s - loss: 0.6243 - acc: 0.8971
3300/4800 [===================>..........] - ETA: 0s - loss: 0.6242 - acc: 0.8959
3600/4800 [=====================>........] - ETA: 0s - loss: 0.6231 - acc: 0.8971
3900/4800 [=======================>......] - ETA: 0s - loss: 0.6230 - acc: 0.8969
4200/4800 [=========================>....] - ETA: 0s - loss: 0.6225 - acc: 0.8963
4500/4800 [===========================>..] - ETA: 0s - loss: 0.6232 - acc: 0.8951
4800/4800 [==============================] - 3s 543us/step - loss: 0.6224 - acc: 0.8951 - val_loss: 0.5626 - val_acc: 0.8943
Epoch 3/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.6151 - acc: 0.8982
 600/4800 [==>...........................] - ETA: 1s - loss: 0.6130 - acc: 0.8923
 900/4800 [====>.........................] - ETA: 1s - loss: 0.6170 - acc: 0.8969
1200/4800 [======>.......................] - ETA: 1s - loss: 0.6221 - acc: 0.8888
1500/4800 [========>.....................] - ETA: 1s - loss: 0.6223 - acc: 0.8905
1800/4800 [==========>...................] - ETA: 1s - loss: 0.6217 - acc: 0.8924
2100/4800 [============>.................] - ETA: 1s - loss: 0.6209 - acc: 0.8942
2400/4800 [==============>...............] - ETA: 1s - loss: 0.6204 - acc: 0.8946
2700/4800 [===============>..............] - ETA: 1s - loss: 0.6201 - acc: 0.8973
3000/4800 [=================>............] - ETA: 0s - loss: 0.6199 - acc: 0.8995
3300/4800 [===================>..........] - ETA: 0s - loss: 0.6202 - acc: 0.8985
3600/4800 [=====================>........] - ETA: 0s - loss: 0.6199 - acc: 0.8984
3900/4800 [=======================>......] - ETA: 0s - loss: 0.6193 - acc: 0.8983
4200/4800 [=========================>....] - ETA: 0s - loss: 0.6198 - acc: 0.8973
4500/4800 [===========================>..] - ETA: 0s - loss: 0.6192 - acc: 0.8978
4800/4800 [==============================] - 3s 540us/step - loss: 0.6198 - acc: 0.8958 - val_loss: 0.5591 - val_acc: 0.8943
Epoch 4/20

 300/4800 [>.............................] - ETA: 1s - loss: 0.6085 - acc: 0.9152
 600/4800 [==>...........................] - ETA: 1s - loss: 0.6166 - acc: 0.9053
 900/4800 [====>.........................] - ETA: 1s - loss: 0.6146 - acc: 0.9106
1200/4800 [======>.......................] - ETA: 1s - loss: 0.6153 - acc: 0.9064
1500/4800 [========>.....................] - ETA: 1s - loss: 0.6184 - acc: 0.9003
1800/4800 [==========>...................] - ETA: 1s - loss: 0.6180 - acc: 0.9012
2100/4800 [============>.................] - ETA: 1s - loss: 0.6182 - acc: 0.9020
2400/4800 [==============>...............] - ETA: 1s - loss: 0.6194 - acc: 0.8981
2700/4800 [===============>..............] - ETA: 1s - loss: 0.6189 - acc: 0.8979
3000/4800 [=================>............] - ETA: 0s - loss: 0.6185 - acc: 0.8992
3300/4800 [===================>..........] - ETA: 0s - loss: 0.6170 - acc: 0.9001
3600/4800 [=====================>........] - ETA: 0s - loss: 0.6174 - acc: 0.8979
3900/4800 [=======================>......] - ETA: 0s - loss: 0.6172 - acc: 0.8963
4200/4800 [=========================>....] - ETA: 0s - loss: 0.6170 - acc: 0.8956
4500/4800 [===========================>..] - ETA: 0s - loss: 0.6175 - acc: 0.8954
4800/4800 [==============================] - 3s 537us/step - loss: 0.6178 - acc: 0.8959 - val_loss: 0.5484 - val_acc: 0.8943
Epoch 5/20

 300/4800 [>.............................] - ETA: 1s - loss: 0.6100 - acc: 0.8926
 600/4800 [==>...........................] - ETA: 1s - loss: 0.6133 - acc: 0.8895
 900/4800 [====>.........................] - ETA: 1s - loss: 0.6159 - acc: 0.8915
1200/4800 [======>.......................] - ETA: 1s - loss: 0.6162 - acc: 0.8944
1500/4800 [========>.....................] - ETA: 1s - loss: 0.6169 - acc: 0.8932
1800/4800 [==========>...................] - ETA: 1s - loss: 0.6167 - acc: 0.8945
2100/4800 [============>.................] - ETA: 1s - loss: 0.6169 - acc: 0.8934
2400/4800 [==============>...............] - ETA: 1s - loss: 0.6162 - acc: 0.8946
2700/4800 [===============>..............] - ETA: 1s - loss: 0.6161 - acc: 0.8938
3000/4800 [=================>............] - ETA: 0s - loss: 0.6152 - acc: 0.8956
3300/4800 [===================>..........] - ETA: 0s - loss: 0.6152 - acc: 0.8957
3600/4800 [=====================>........] - ETA: 0s - loss: 0.6154 - acc: 0.8968
3900/4800 [=======================>......] - ETA: 0s - loss: 0.6152 - acc: 0.8959
4200/4800 [=========================>....] - ETA: 0s - loss: 0.6149 - acc: 0.8956
4500/4800 [===========================>..] - ETA: 0s - loss: 0.6147 - acc: 0.8952
4800/4800 [==============================] - 3s 537us/step - loss: 0.6145 - acc: 0.8952 - val_loss: 0.5107 - val_acc: 0.8943
Epoch 6/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.6092 - acc: 0.9142
 600/4800 [==>...........................] - ETA: 2s - loss: 0.6090 - acc: 0.9101
 900/4800 [====>.........................] - ETA: 1s - loss: 0.6088 - acc: 0.9028
1200/4800 [======>.......................] - ETA: 1s - loss: 0.6103 - acc: 0.8983
1500/4800 [========>.....................] - ETA: 1s - loss: 0.6110 - acc: 0.9013
1800/4800 [==========>...................] - ETA: 1s - loss: 0.6101 - acc: 0.9019
2100/4800 [============>.................] - ETA: 1s - loss: 0.6096 - acc: 0.8982
2400/4800 [==============>...............] - ETA: 1s - loss: 0.6099 - acc: 0.8978
2700/4800 [===============>..............] - ETA: 1s - loss: 0.6096 - acc: 0.8973
3000/4800 [=================>............] - ETA: 0s - loss: 0.6101 - acc: 0.8974
3300/4800 [===================>..........] - ETA: 0s - loss: 0.6096 - acc: 0.8980
3600/4800 [=====================>........] - ETA: 0s - loss: 0.6091 - acc: 0.8976
3900/4800 [=======================>......] - ETA: 0s - loss: 0.6086 - acc: 0.8967
4200/4800 [=========================>....] - ETA: 0s - loss: 0.6076 - acc: 0.8965
4500/4800 [===========================>..] - ETA: 0s - loss: 0.6071 - acc: 0.8958
4800/4800 [==============================] - 3s 534us/step - loss: 0.6068 - acc: 0.8961 - val_loss: 0.4959 - val_acc: 0.8943
Epoch 7/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.6077 - acc: 0.9021
 600/4800 [==>...........................] - ETA: 1s - loss: 0.6073 - acc: 0.9044
 900/4800 [====>.........................] - ETA: 1s - loss: 0.6079 - acc: 0.9028
1200/4800 [======>.......................] - ETA: 1s - loss: 0.6063 - acc: 0.8994
1500/4800 [========>.....................] - ETA: 1s - loss: 0.6046 - acc: 0.8995
1800/4800 [==========>...................] - ETA: 1s - loss: 0.6030 - acc: 0.8982
2100/4800 [============>.................] - ETA: 1s - loss: 0.6028 - acc: 0.8996
2400/4800 [==============>...............] - ETA: 1s - loss: 0.6020 - acc: 0.9016
2700/4800 [===============>..............] - ETA: 0s - loss: 0.6016 - acc: 0.8980
3000/4800 [=================>............] - ETA: 0s - loss: 0.6018 - acc: 0.8987
3300/4800 [===================>..........] - ETA: 0s - loss: 0.6018 - acc: 0.8965
3600/4800 [=====================>........] - ETA: 0s - loss: 0.6020 - acc: 0.8951
3900/4800 [=======================>......] - ETA: 0s - loss: 0.6016 - acc: 0.8955
4200/4800 [=========================>....] - ETA: 0s - loss: 0.6022 - acc: 0.8943
4500/4800 [===========================>..] - ETA: 0s - loss: 0.6020 - acc: 0.8951
4800/4800 [==============================] - 3s 529us/step - loss: 0.6016 - acc: 0.8958 - val_loss: 0.4809 - val_acc: 0.8943
Epoch 8/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5876 - acc: 0.8943
 600/4800 [==>...........................] - ETA: 1s - loss: 0.5959 - acc: 0.8885
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5968 - acc: 0.8913
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5984 - acc: 0.8958
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5982 - acc: 0.8973
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5989 - acc: 0.8911
2100/4800 [============>.................] - ETA: 1s - loss: 0.5980 - acc: 0.8940
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5985 - acc: 0.8928
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5984 - acc: 0.8921
3000/4800 [=================>............] - ETA: 0s - loss: 0.5983 - acc: 0.8928
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5979 - acc: 0.8924
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5973 - acc: 0.8934
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5966 - acc: 0.8940
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5971 - acc: 0.8942
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5968 - acc: 0.8954
4800/4800 [==============================] - 3s 541us/step - loss: 0.5969 - acc: 0.8960 - val_loss: 0.4254 - val_acc: 0.8943
Epoch 9/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5972 - acc: 0.8802
 600/4800 [==>...........................] - ETA: 2s - loss: 0.6006 - acc: 0.8819
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5972 - acc: 0.8820
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5969 - acc: 0.8859
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5947 - acc: 0.8900
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5947 - acc: 0.8923
2100/4800 [============>.................] - ETA: 1s - loss: 0.5937 - acc: 0.8926
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5938 - acc: 0.8932
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5945 - acc: 0.8935
3000/4800 [=================>............] - ETA: 0s - loss: 0.5947 - acc: 0.8951
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5956 - acc: 0.8940
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5950 - acc: 0.8937
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5953 - acc: 0.8963
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5950 - acc: 0.8959
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5948 - acc: 0.8960
4800/4800 [==============================] - 3s 547us/step - loss: 0.5946 - acc: 0.8961 - val_loss: 0.4401 - val_acc: 0.8943
Epoch 10/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5971 - acc: 0.8836
 600/4800 [==>...........................] - ETA: 1s - loss: 0.5953 - acc: 0.8874
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5943 - acc: 0.8965
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5949 - acc: 0.8924
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5917 - acc: 0.8961
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5930 - acc: 0.8958
2100/4800 [============>.................] - ETA: 1s - loss: 0.5929 - acc: 0.8946
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5933 - acc: 0.8949
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5935 - acc: 0.8951
3000/4800 [=================>............] - ETA: 0s - loss: 0.5935 - acc: 0.8948
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5932 - acc: 0.8942
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5934 - acc: 0.8948
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5933 - acc: 0.8942
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5935 - acc: 0.8957
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5934 - acc: 0.8961
4800/4800 [==============================] - 3s 528us/step - loss: 0.5933 - acc: 0.8963 - val_loss: 0.4126 - val_acc: 0.8943
Epoch 11/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5971 - acc: 0.8942
 600/4800 [==>...........................] - ETA: 1s - loss: 0.5917 - acc: 0.8958
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5898 - acc: 0.8970
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5904 - acc: 0.8986
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5910 - acc: 0.8949
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5916 - acc: 0.8950
2100/4800 [============>.................] - ETA: 1s - loss: 0.5917 - acc: 0.8948
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5923 - acc: 0.8925
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5916 - acc: 0.8951
3000/4800 [=================>............] - ETA: 0s - loss: 0.5919 - acc: 0.8955
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5924 - acc: 0.8945
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5924 - acc: 0.8953
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5924 - acc: 0.8960
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5928 - acc: 0.8953
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5929 - acc: 0.8955
4800/4800 [==============================] - 3s 545us/step - loss: 0.5923 - acc: 0.8963 - val_loss: 0.4471 - val_acc: 0.8943
Epoch 12/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5845 - acc: 0.9104
 600/4800 [==>...........................] - ETA: 2s - loss: 0.5898 - acc: 0.9015
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5886 - acc: 0.9016
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5907 - acc: 0.8960
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5926 - acc: 0.8934
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5918 - acc: 0.8938
2100/4800 [============>.................] - ETA: 1s - loss: 0.5920 - acc: 0.8949
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5925 - acc: 0.8940
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5924 - acc: 0.8971
3000/4800 [=================>............] - ETA: 0s - loss: 0.5927 - acc: 0.8958
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5928 - acc: 0.8962
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5929 - acc: 0.8956
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5927 - acc: 0.8960
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5925 - acc: 0.8963
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5928 - acc: 0.8956
4800/4800 [==============================] - 3s 548us/step - loss: 0.5925 - acc: 0.8963 - val_loss: 0.4098 - val_acc: 0.8943
Epoch 13/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5952 - acc: 0.9053
 600/4800 [==>...........................] - ETA: 2s - loss: 0.5927 - acc: 0.9000
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5929 - acc: 0.8990
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5908 - acc: 0.8988
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5902 - acc: 0.8998
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5916 - acc: 0.8966
2100/4800 [============>.................] - ETA: 1s - loss: 0.5912 - acc: 0.8970
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5912 - acc: 0.8993
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5923 - acc: 0.8973
3000/4800 [=================>............] - ETA: 0s - loss: 0.5918 - acc: 0.8981
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5910 - acc: 0.8974
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5919 - acc: 0.8951
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5919 - acc: 0.8950
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5919 - acc: 0.8960
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5917 - acc: 0.8970
4800/4800 [==============================] - 3s 544us/step - loss: 0.5915 - acc: 0.8963 - val_loss: 0.4086 - val_acc: 0.8943
Epoch 14/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5873 - acc: 0.9111
 600/4800 [==>...........................] - ETA: 2s - loss: 0.5886 - acc: 0.9041
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5919 - acc: 0.8926
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5920 - acc: 0.8952
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5908 - acc: 0.8989
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5892 - acc: 0.8981
2100/4800 [============>.................] - ETA: 1s - loss: 0.5897 - acc: 0.8991
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5900 - acc: 0.9002
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5898 - acc: 0.8996
3000/4800 [=================>............] - ETA: 0s - loss: 0.5894 - acc: 0.9010
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5893 - acc: 0.9008
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5899 - acc: 0.8983
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5902 - acc: 0.8986
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5905 - acc: 0.8970
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5904 - acc: 0.8960
4800/4800 [==============================] - 3s 552us/step - loss: 0.5902 - acc: 0.8963 - val_loss: 0.3959 - val_acc: 0.8943
Epoch 15/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5848 - acc: 0.9110
 600/4800 [==>...........................] - ETA: 2s - loss: 0.5865 - acc: 0.9152
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5894 - acc: 0.9042
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5907 - acc: 0.8979
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5912 - acc: 0.8964
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5923 - acc: 0.8948
2100/4800 [============>.................] - ETA: 1s - loss: 0.5918 - acc: 0.8979
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5907 - acc: 0.9000
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5909 - acc: 0.8970
3000/4800 [=================>............] - ETA: 0s - loss: 0.5908 - acc: 0.8948
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5906 - acc: 0.8962
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5899 - acc: 0.8961
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5899 - acc: 0.8950
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5896 - acc: 0.8942
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5892 - acc: 0.8958
4800/4800 [==============================] - 3s 541us/step - loss: 0.5891 - acc: 0.8963 - val_loss: 0.3921 - val_acc: 0.8943
Epoch 16/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5805 - acc: 0.9089
 600/4800 [==>...........................] - ETA: 2s - loss: 0.5864 - acc: 0.8912
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5837 - acc: 0.8959
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5850 - acc: 0.8947
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5861 - acc: 0.8965
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5871 - acc: 0.8962
2100/4800 [============>.................] - ETA: 1s - loss: 0.5875 - acc: 0.8992
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5877 - acc: 0.8973
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5879 - acc: 0.8978
3000/4800 [=================>............] - ETA: 0s - loss: 0.5877 - acc: 0.8984
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5884 - acc: 0.8984
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5876 - acc: 0.9002
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5880 - acc: 0.8995
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5883 - acc: 0.8977
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5885 - acc: 0.8966
4800/4800 [==============================] - 3s 532us/step - loss: 0.5887 - acc: 0.8963 - val_loss: 0.3856 - val_acc: 0.8943
Epoch 17/20

 300/4800 [>.............................] - ETA: 1s - loss: 0.5920 - acc: 0.8827
 600/4800 [==>...........................] - ETA: 1s - loss: 0.5923 - acc: 0.8871
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5918 - acc: 0.8904
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5922 - acc: 0.8866
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5925 - acc: 0.8906
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5930 - acc: 0.8921
2100/4800 [============>.................] - ETA: 1s - loss: 0.5913 - acc: 0.8944
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5905 - acc: 0.8961
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5903 - acc: 0.8938
3000/4800 [=================>............] - ETA: 0s - loss: 0.5898 - acc: 0.8923
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5894 - acc: 0.8940
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5901 - acc: 0.8931
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5888 - acc: 0.8950
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5886 - acc: 0.8962
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5878 - acc: 0.8962
4800/4800 [==============================] - 3s 546us/step - loss: 0.5883 - acc: 0.8963 - val_loss: 0.3934 - val_acc: 0.8943
Epoch 18/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5845 - acc: 0.9140
 600/4800 [==>...........................] - ETA: 2s - loss: 0.5846 - acc: 0.9052
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5830 - acc: 0.9064
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5823 - acc: 0.9075
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5824 - acc: 0.9049
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5833 - acc: 0.9073
2100/4800 [============>.................] - ETA: 1s - loss: 0.5842 - acc: 0.9056
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5849 - acc: 0.9052
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5845 - acc: 0.9031
3000/4800 [=================>............] - ETA: 0s - loss: 0.5843 - acc: 0.9033
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5855 - acc: 0.9005
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5867 - acc: 0.8980
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5872 - acc: 0.8977
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5870 - acc: 0.8980
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5879 - acc: 0.8970
4800/4800 [==============================] - 3s 541us/step - loss: 0.5874 - acc: 0.8963 - val_loss: 0.3779 - val_acc: 0.8943
Epoch 19/20

 300/4800 [>.............................] - ETA: 1s - loss: 0.5930 - acc: 0.9015
 600/4800 [==>...........................] - ETA: 1s - loss: 0.5906 - acc: 0.8996
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5887 - acc: 0.8981
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5876 - acc: 0.8968
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5887 - acc: 0.8935
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5882 - acc: 0.8917
2100/4800 [============>.................] - ETA: 1s - loss: 0.5879 - acc: 0.8909
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5873 - acc: 0.8916
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5873 - acc: 0.8936
3000/4800 [=================>............] - ETA: 0s - loss: 0.5877 - acc: 0.8927
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5878 - acc: 0.8928
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5875 - acc: 0.8936
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5873 - acc: 0.8961
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5874 - acc: 0.8956
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5875 - acc: 0.8954
4800/4800 [==============================] - 3s 547us/step - loss: 0.5870 - acc: 0.8963 - val_loss: 0.3925 - val_acc: 0.8943
Epoch 20/20

 300/4800 [>.............................] - ETA: 1s - loss: 0.5865 - acc: 0.9077
 600/4800 [==>...........................] - ETA: 1s - loss: 0.5865 - acc: 0.8930
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5844 - acc: 0.8977
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5860 - acc: 0.8892
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5868 - acc: 0.8906
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5879 - acc: 0.8883
2100/4800 [============>.................] - ETA: 1s - loss: 0.5863 - acc: 0.8927
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5857 - acc: 0.8929
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5867 - acc: 0.8932
3000/4800 [=================>............] - ETA: 0s - loss: 0.5856 - acc: 0.8933
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5859 - acc: 0.8927
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5854 - acc: 0.8948
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5857 - acc: 0.8953
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5861 - acc: 0.8954
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5868 - acc: 0.8955
4800/4800 [==============================] - 3s 541us/step - loss: 0.5866 - acc: 0.8963 - val_loss: 0.3900 - val_acc: 0.8943
C:\Anaconda3\lib\site-packages\h5py\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
Finished
