----------------------------------
- Parameters.py                  -
----------------------------------
data_params = {
    "width"                 : 640,
    "height"                : 480,
    "labelled_train_db"     : 'data/labels.train.db',
    "labelled_train_dir"    : 'data/labelled.train/',
    "labelled_validate_db"  : 'data/labels.validate.db',
    "labelled_validate_dir" : 'data/labelled.validate/',
    "segmented_dir"         : 'data/segmented/'
}

model_params = {
    "num_classes" : 2,
    "batch_size"  : 300,
    "epochs"      : 20
}

hyper_params = {
    "max_training_images_count"    : 100,     # if value is -1 then take all training images
    "max_testing_images_count"     : -1,      # if value is -1 then take all training images
    "l2_regularisation"            : 0.0005,
    "dropout"                      : 0.50,
    "learning_rate"                : 0.0001,
    "percentage_train"             : 80,
    "windows_per_image_on_average" : 60,
    "window_size"                  : 40,
    "bee_radius"                   : 20,
    "min_bee_prob"                 : 0.80,
    "max_bee_prob"                 : 1.00,
    "min_bee_prct_window"          : 45.0,
    "bee_window_percentage"        : 20,
    "filters_count"                : 32,
    "kernel_size"                  : 3,
    "padding_to_remove"            : 4,
    "sliding_window_step"          : 2
}
----------------------------------
- Training                       -
----------------------------------
Data Parameters:
Key: width, Value: 640
Key: height, Value: 480
Key: labelled_train_db, Value: data/labels.train.db
Key: labelled_train_dir, Value: data/labelled.train/
Key: labelled_validate_db, Value: data/labels.validate.db
Key: labelled_validate_dir, Value: data/labelled.validate/
Key: segmented_dir, Value: data/segmented/
Model Parameters:
Key: num_classes, Value: 2
Key: batch_size, Value: 300
Key: epochs, Value: 20
Hyper Parameters:
Key: max_training_images_count, Value: 100
Key: max_testing_images_count, Value: -1
Key: l2_regularisation, Value: 0.0005
Key: dropout, Value: 0.5
Key: learning_rate, Value: 0.0001
Key: percentage_train, Value: 80
Key: windows_per_image_on_average, Value: 60
Key: window_size, Value: 40
Key: bee_radius, Value: 20
Key: min_bee_prob, Value: 0.8
Key: max_bee_prob, Value: 1.0
Key: min_bee_prct_window, Value: 45.0
Key: bee_window_percentage, Value: 20
Key: filters_count, Value: 32
Key: kernel_size, Value: 3
Key: padding_to_remove, Value: 4
Key: sliding_window_step, Value: 2
Index is 65
Index is 65
Index is 96
Index is 19
Index is 78
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 40, 40, 3)    0                                            
__________________________________________________________________________________________________
conv1_1 (Conv2D)                (None, 40, 40, 32)   896         input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 40, 40, 32)   9248        conv1_1[0][0]                    
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 20, 20, 32)   0           conv2d_1[0][0]                   
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 20, 20, 64)   18496       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 20, 20, 64)   36928       conv2d_2[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 10, 10, 64)   0           conv2d_3[0][0]                   
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 10, 10, 128)  73856       max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 10, 10, 128)  147584      conv2d_4[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 128)    0           conv2d_5[0][0]                   
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 5, 5, 256)    295168      max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 5, 5, 256)    590080      conv2d_6[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)  (None, 2, 2, 256)    0           conv2d_7[0][0]                   
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 2, 2, 512)    1180160     max_pooling2d_4[0][0]            
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 2, 2, 512)    2359808     conv2d_8[0][0]                   
__________________________________________________________________________________________________
up_sampling2d_1 (UpSampling2D)  (None, 4, 4, 512)    0           conv2d_9[0][0]                   
__________________________________________________________________________________________________
cropping2d_1 (Cropping2D)       (None, 4, 4, 256)    0           conv2d_7[0][0]                   
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 4, 4, 768)    0           up_sampling2d_1[0][0]            
                                                                 cropping2d_1[0][0]               
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 4, 4, 256)    1769728     concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 4, 4, 256)    590080      conv2d_10[0][0]                  
__________________________________________________________________________________________________
up_sampling2d_2 (UpSampling2D)  (None, 8, 8, 256)    0           conv2d_11[0][0]                  
__________________________________________________________________________________________________
cropping2d_2 (Cropping2D)       (None, 8, 8, 128)    0           conv2d_5[0][0]                   
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 8, 8, 384)    0           up_sampling2d_2[0][0]            
                                                                 cropping2d_2[0][0]               
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 8, 8, 128)    442496      concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 8, 8, 128)    147584      conv2d_12[0][0]                  
__________________________________________________________________________________________________
up_sampling2d_3 (UpSampling2D)  (None, 16, 16, 128)  0           conv2d_13[0][0]                  
__________________________________________________________________________________________________
cropping2d_3 (Cropping2D)       (None, 16, 16, 64)   0           conv2d_3[0][0]                   
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 16, 16, 192)  0           up_sampling2d_3[0][0]            
                                                                 cropping2d_3[0][0]               
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 16, 16, 64)   110656      concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 16, 16, 64)   36928       conv2d_14[0][0]                  
__________________________________________________________________________________________________
up_sampling2d_4 (UpSampling2D)  (None, 32, 32, 64)   0           conv2d_15[0][0]                  
__________________________________________________________________________________________________
cropping2d_4 (Cropping2D)       (None, 32, 32, 32)   0           conv2d_1[0][0]                   
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 32, 32, 96)   0           up_sampling2d_4[0][0]            2019-04-28 20:12:13.841725: I T:\src\github\tensorflow\tensorflow\core\platform\cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2019-04-28 20:12:14.142628: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1405] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.8095
pciBusID: 0000:65:00.0
totalMemory: 8.00GiB freeMemory: 6.59GiB
2019-04-28 20:12:14.143906: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1484] Adding visible gpu devices: 0
2019-04-28 20:12:14.966879: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-04-28 20:12:14.967664: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:971]      0 
2019-04-28 20:12:14.968177: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:984] 0:   N 
2019-04-28 20:12:14.968821: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6360 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:65:00.0, compute capability: 6.1)

                                                                 cropping2d_4[0][0]               
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 32, 32, 32)   27680       concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 32, 32, 32)   9248        conv2d_16[0][0]                  
__________________________________________________________________________________________________
zero_padding2d_1 (ZeroPadding2D (None, 40, 40, 32)   0           conv2d_17[0][0]                  
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 40, 40, 2)    66          zero_padding2d_1[0][0]           
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 40, 40, 2)    0           conv2d_18[0][0]                  
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 40, 40, 2)    0           activation_1[0][0]               
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 40, 40, 2)    0           dropout_1[0][0]                  
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 40, 40, 2)    0           activation_2[0][0]               
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 40, 2)    0           dropout_2[0][0]                  
==================================================================================================
Total params: 7,846,690
Trainable params: 7,846,690
Non-trainable params: 0
__________________________________________________________________________________________________
Analysing training image 0 out of 100 images
Analysing training image 1 out of 100 images
Analysing training image 2 out of 100 images
Analysing training image 3 out of 100 images
Analysing training image 4 out of 100 images
Analysing training image 5 out of 100 images
Analysing training image 6 out of 100 images
Analysing training image 7 out of 100 images
Analysing training image 8 out of 100 images
Analysing training image 9 out of 100 images
Analysing training image 10 out of 100 images
Analysing training image 11 out of 100 images
Analysing training image 12 out of 100 images
Analysing training image 13 out of 100 images
Analysing training image 14 out of 100 images
Analysing training image 15 out of 100 images
Analysing training image 16 out of 100 images
Analysing training image 17 out of 100 images
Analysing training image 18 out of 100 images
Analysing training image 19 out of 100 images
Analysing training image 20 out of 100 images
Analysing training image 21 out of 100 images
Analysing training image 22 out of 100 images
Analysing training image 23 out of 100 images
Analysing training image 24 out of 100 images
Analysing training image 25 out of 100 images
Analysing training image 26 out of 100 images
Analysing training image 27 out of 100 images
Analysing training image 28 out of 100 images
Analysing training image 29 out of 100 images
Analysing training image 30 out of 100 images
Analysing training image 31 out of 100 images
Analysing training image 32 out of 100 images
Analysing training image 33 out of 100 images
Analysing training image 34 out of 100 images
Analysing training image 35 out of 100 images
Analysing training image 36 out of 100 images
Analysing training image 37 out of 100 images
Analysing training image 38 out of 100 images
Analysing training image 39 out of 100 images
Analysing training image 40 out of 100 images
Analysing training image 41 out of 100 images
Analysing training image 42 out of 100 images
Analysing training image 43 out of 100 images
Analysing training image 44 out of 100 images
Analysing training image 45 out of 100 images
Analysing training image 46 out of 100 images
Analysing training image 47 out of 100 images
Analysing training image 48 out of 100 images
Analysing training image 49 out of 100 images
Analysing training image 50 out of 100 images
Analysing training image 51 out of 100 images
Analysing training image 52 out of 100 images
Analysing training image 53 out of 100 images
Analysing training image 54 out of 100 images
Analysing training image 55 out of 100 images
Analysing training image 56 out of 100 images
Analysing training image 57 out of 100 images
Analysing training image 58 out of 100 images
Analysing training image 59 out of 100 images
Analysing training image 60 out of 100 images
Analysing training image 61 out of 100 images
Analysing training image 62 out of 100 images
Analysing training image 63 out of 100 images
Analysing training image 64 out of 100 images
Analysing training image 65 out of 100 images
Analysing training image 66 out of 100 images
Analysing training image 67 out of 100 images
Analysing training image 68 out of 100 images
Analysing training image 69 out of 100 images
Analysing training image 70 out of 100 images
Analysing training image 71 out of 100 images
Analysing training image 72 out of 100 images
Analysing training image 73 out of 100 images
Analysing training image 74 out of 100 images
Analysing training image 75 out of 100 images
Analysing training image 76 out of 100 images
Analysing training image 77 out of 100 images
Analysing training image 78 out of 100 images
Analysing training image 79 out of 100 images
Analysing training image 80 out of 100 images
Analysing training image 81 out of 100 images
Analysing training image 82 out of 100 images
Analysing training image 83 out of 100 images
Analysing training image 84 out of 100 images
Analysing training image 85 out of 100 images
Analysing training image 86 out of 100 images
Analysing training image 87 out of 100 images
Analysing training image 88 out of 100 images
Analysing training image 89 out of 100 images
Analysing training image 90 out of 100 images
Analysing training image 91 out of 100 images
Analysing training image 92 out of 100 images
Analysing training image 93 out of 100 images
Analysing training image 94 out of 100 images
Analysing training image 95 out of 100 images
Analysing training image 96 out of 100 images
Analysing training image 97 out of 100 images
Analysing training image 98 out of 100 images
Analysing training image 99 out of 100 images
Train on 4800 samples, validate on 1200 samples
Epoch 1/20

 300/4800 [>.............................] - ETA: 1:27 - loss: 0.6611 - acc: 0.8975
 600/4800 [==>...........................] - ETA: 41s - loss: 0.6603 - acc: 0.8964 
 900/4800 [====>.........................] - ETA: 26s - loss: 0.6590 - acc: 0.9009
1200/4800 [======>.......................] - ETA: 18s - loss: 0.6596 - acc: 0.8968
1500/4800 [========>.....................] - ETA: 14s - loss: 0.6601 - acc: 0.8972
1800/4800 [==========>...................] - ETA: 10s - loss: 0.6599 - acc: 0.8960
2100/4800 [============>.................] - ETA: 8s - loss: 0.6590 - acc: 0.8979 
2400/4800 [==============>...............] - ETA: 6s - loss: 0.6585 - acc: 0.8956
2700/4800 [===============>..............] - ETA: 5s - loss: 0.6567 - acc: 0.8953
3000/4800 [=================>............] - ETA: 4s - loss: 0.6549 - acc: 0.8956
3300/4800 [===================>..........] - ETA: 3s - loss: 0.6524 - acc: 0.8943
3600/4800 [=====================>........] - ETA: 2s - loss: 0.6510 - acc: 0.8944
3900/4800 [=======================>......] - ETA: 1s - loss: 0.6494 - acc: 0.8953
4200/4800 [=========================>....] - ETA: 1s - loss: 0.6480 - acc: 0.8947
4500/4800 [===========================>..] - ETA: 0s - loss: 0.6470 - acc: 0.8945
4800/4800 [==============================] - 8s 2ms/step - loss: 0.6464 - acc: 0.8944 - val_loss: 0.5544 - val_acc: 0.8970
Epoch 2/20

 300/4800 [>.............................] - ETA: 1s - loss: 0.6390 - acc: 0.8817
 600/4800 [==>...........................] - ETA: 2s - loss: 0.6336 - acc: 0.8878
 900/4800 [====>.........................] - ETA: 1s - loss: 0.6319 - acc: 0.8888
1200/4800 [======>.......................] - ETA: 1s - loss: 0.6304 - acc: 0.8897
1500/4800 [========>.....................] - ETA: 1s - loss: 0.6271 - acc: 0.8893
1800/4800 [==========>...................] - ETA: 1s - loss: 0.6269 - acc: 0.8926
2100/4800 [============>.................] - ETA: 1s - loss: 0.6258 - acc: 0.8925
2400/4800 [==============>...............] - ETA: 1s - loss: 0.6265 - acc: 0.8894
2700/4800 [===============>..............] - ETA: 1s - loss: 0.6266 - acc: 0.8900
3000/4800 [=================>............] - ETA: 0s - loss: 0.6266 - acc: 0.8914
3300/4800 [===================>..........] - ETA: 0s - loss: 0.6260 - acc: 0.8922
3600/4800 [=====================>........] - ETA: 0s - loss: 0.6252 - acc: 0.8924
3900/4800 [=======================>......] - ETA: 0s - loss: 0.6244 - acc: 0.8931
4200/4800 [=========================>....] - ETA: 0s - loss: 0.6244 - acc: 0.8925
4500/4800 [===========================>..] - ETA: 0s - loss: 0.6236 - acc: 0.8937
4800/4800 [==============================] - 3s 553us/step - loss: 0.6235 - acc: 0.8950 - val_loss: 0.5582 - val_acc: 0.8970
Epoch 3/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.6225 - acc: 0.8964
 600/4800 [==>...........................] - ETA: 2s - loss: 0.6210 - acc: 0.8958
 900/4800 [====>.........................] - ETA: 1s - loss: 0.6207 - acc: 0.8963
1200/4800 [======>.......................] - ETA: 1s - loss: 0.6190 - acc: 0.9008
1500/4800 [========>.....................] - ETA: 1s - loss: 0.6204 - acc: 0.8996
1800/4800 [==========>...................] - ETA: 1s - loss: 0.6208 - acc: 0.8958
2100/4800 [============>.................] - ETA: 1s - loss: 0.6215 - acc: 0.8915
2400/4800 [==============>...............] - ETA: 1s - loss: 0.6204 - acc: 0.8919
2700/4800 [===============>..............] - ETA: 1s - loss: 0.6191 - acc: 0.8926
3000/4800 [=================>............] - ETA: 0s - loss: 0.6193 - acc: 0.8940
3300/4800 [===================>..........] - ETA: 0s - loss: 0.6200 - acc: 0.8928
3600/4800 [=====================>........] - ETA: 0s - loss: 0.6187 - acc: 0.8945
3900/4800 [=======================>......] - ETA: 0s - loss: 0.6183 - acc: 0.8958
4200/4800 [=========================>....] - ETA: 0s - loss: 0.6181 - acc: 0.8959
4500/4800 [===========================>..] - ETA: 0s - loss: 0.6188 - acc: 0.8948
4800/4800 [==============================] - 3s 549us/step - loss: 0.6193 - acc: 0.8950 - val_loss: 0.5586 - val_acc: 0.8970
Epoch 4/20

 300/4800 [>.............................] - ETA: 1s - loss: 0.6138 - acc: 0.9092
 600/4800 [==>...........................] - ETA: 1s - loss: 0.6164 - acc: 0.9041
 900/4800 [====>.........................] - ETA: 1s - loss: 0.6165 - acc: 0.9046
1200/4800 [======>.......................] - ETA: 1s - loss: 0.6156 - acc: 0.9049
1500/4800 [========>.....................] - ETA: 1s - loss: 0.6169 - acc: 0.8988
1800/4800 [==========>...................] - ETA: 1s - loss: 0.6168 - acc: 0.8997
2100/4800 [============>.................] - ETA: 1s - loss: 0.6170 - acc: 0.8997
2400/4800 [==============>...............] - ETA: 1s - loss: 0.6165 - acc: 0.9016
2700/4800 [===============>..............] - ETA: 1s - loss: 0.6155 - acc: 0.9005
3000/4800 [=================>............] - ETA: 0s - loss: 0.6154 - acc: 0.9007
3300/4800 [===================>..........] - ETA: 0s - loss: 0.6153 - acc: 0.9004
3600/4800 [=====================>........] - ETA: 0s - loss: 0.6154 - acc: 0.8999
3900/4800 [=======================>......] - ETA: 0s - loss: 0.6164 - acc: 0.8981
4200/4800 [=========================>....] - ETA: 0s - loss: 0.6167 - acc: 0.8976
4500/4800 [===========================>..] - ETA: 0s - loss: 0.6160 - acc: 0.8977
4800/4800 [==============================] - 3s 545us/step - loss: 0.6165 - acc: 0.8956 - val_loss: 0.5490 - val_acc: 0.8970
Epoch 5/20

 300/4800 [>.............................] - ETA: 1s - loss: 0.6096 - acc: 0.8753
 600/4800 [==>...........................] - ETA: 1s - loss: 0.6132 - acc: 0.8816
 900/4800 [====>.........................] - ETA: 1s - loss: 0.6125 - acc: 0.8929
1200/4800 [======>.......................] - ETA: 1s - loss: 0.6137 - acc: 0.8924
1500/4800 [========>.....................] - ETA: 1s - loss: 0.6147 - acc: 0.8885
1800/4800 [==========>...................] - ETA: 1s - loss: 0.6144 - acc: 0.8909
2100/4800 [============>.................] - ETA: 1s - loss: 0.6134 - acc: 0.8922
2400/4800 [==============>...............] - ETA: 1s - loss: 0.6117 - acc: 0.8947
2700/4800 [===============>..............] - ETA: 1s - loss: 0.6122 - acc: 0.8948
3000/4800 [=================>............] - ETA: 0s - loss: 0.6119 - acc: 0.8970
3300/4800 [===================>..........] - ETA: 0s - loss: 0.6113 - acc: 0.8971
3600/4800 [=====================>........] - ETA: 0s - loss: 0.6115 - acc: 0.8966
3900/4800 [=======================>......] - ETA: 0s - loss: 0.6109 - acc: 0.8967
4200/4800 [=========================>....] - ETA: 0s - loss: 0.6109 - acc: 0.8967
4500/4800 [===========================>..] - ETA: 0s - loss: 0.6108 - acc: 0.8961
4800/4800 [==============================] - 3s 547us/step - loss: 0.6109 - acc: 0.8957 - val_loss: 0.5247 - val_acc: 0.8970
Epoch 6/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.6016 - acc: 0.8983
 600/4800 [==>...........................] - ETA: 2s - loss: 0.6054 - acc: 0.8859
 900/4800 [====>.........................] - ETA: 1s - loss: 0.6037 - acc: 0.8916
1200/4800 [======>.......................] - ETA: 1s - loss: 0.6018 - acc: 0.8942
1500/4800 [========>.....................] - ETA: 1s - loss: 0.6028 - acc: 0.8957
1800/4800 [==========>...................] - ETA: 1s - loss: 0.6041 - acc: 0.8942
2100/4800 [============>.................] - ETA: 1s - loss: 0.6058 - acc: 0.8909
2400/4800 [==============>...............] - ETA: 1s - loss: 0.6054 - acc: 0.8915
2700/4800 [===============>..............] - ETA: 1s - loss: 0.6052 - acc: 0.8905
3000/4800 [=================>............] - ETA: 0s - loss: 0.6055 - acc: 0.8912
3300/4800 [===================>..........] - ETA: 0s - loss: 0.6043 - acc: 0.8922
3600/4800 [=====================>........] - ETA: 0s - loss: 0.6038 - acc: 0.8927
3900/4800 [=======================>......] - ETA: 0s - loss: 0.6036 - acc: 0.8934
4200/4800 [=========================>....] - ETA: 0s - loss: 0.6034 - acc: 0.8944
4500/4800 [===========================>..] - ETA: 0s - loss: 0.6026 - acc: 0.8950
4800/4800 [==============================] - 3s 549us/step - loss: 0.6023 - acc: 0.8958 - val_loss: 0.4401 - val_acc: 0.8972
Epoch 7/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5980 - acc: 0.8893
 600/4800 [==>...........................] - ETA: 2s - loss: 0.5989 - acc: 0.8902
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5957 - acc: 0.8950
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5970 - acc: 0.8971
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5964 - acc: 0.8951
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5977 - acc: 0.8925
2100/4800 [============>.................] - ETA: 1s - loss: 0.5976 - acc: 0.8939
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5978 - acc: 0.8942
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5978 - acc: 0.8945
3000/4800 [=================>............] - ETA: 0s - loss: 0.5979 - acc: 0.8948
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5984 - acc: 0.8946
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5982 - acc: 0.8948
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5980 - acc: 0.8972
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5983 - acc: 0.8949
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5978 - acc: 0.8957
4800/4800 [==============================] - 3s 555us/step - loss: 0.5975 - acc: 0.8957 - val_loss: 0.4313 - val_acc: 0.8971
Epoch 8/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5921 - acc: 0.8928
 600/4800 [==>...........................] - ETA: 2s - loss: 0.5946 - acc: 0.8963
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5954 - acc: 0.8970
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5977 - acc: 0.8893
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5986 - acc: 0.8893
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5989 - acc: 0.8871
2100/4800 [============>.................] - ETA: 1s - loss: 0.5988 - acc: 0.8897
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5963 - acc: 0.8933
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5957 - acc: 0.8949
3000/4800 [=================>............] - ETA: 0s - loss: 0.5961 - acc: 0.8952
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5964 - acc: 0.8955
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5964 - acc: 0.8937
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5959 - acc: 0.8951
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5958 - acc: 0.8951
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5955 - acc: 0.8962
4800/4800 [==============================] - 3s 541us/step - loss: 0.5958 - acc: 0.8957 - val_loss: 0.4085 - val_acc: 0.8970
Epoch 9/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.6057 - acc: 0.8756
 600/4800 [==>...........................] - ETA: 2s - loss: 0.5989 - acc: 0.8783
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5968 - acc: 0.8837
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5963 - acc: 0.8931
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5968 - acc: 0.8932
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5973 - acc: 0.8941
2100/4800 [============>.................] - ETA: 1s - loss: 0.5970 - acc: 0.8938
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5962 - acc: 0.8947
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5962 - acc: 0.8948
3000/4800 [=================>............] - ETA: 0s - loss: 0.5965 - acc: 0.8939
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5961 - acc: 0.8946
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5951 - acc: 0.8952
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5950 - acc: 0.8956
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5952 - acc: 0.8947
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5949 - acc: 0.8952
4800/4800 [==============================] - 3s 554us/step - loss: 0.5950 - acc: 0.8957 - val_loss: 0.4393 - val_acc: 0.8970
Epoch 10/20

 300/4800 [>.............................] - ETA: 1s - loss: 0.5870 - acc: 0.8973
 600/4800 [==>...........................] - ETA: 1s - loss: 0.5967 - acc: 0.8800
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5957 - acc: 0.8782
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5947 - acc: 0.8843
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5925 - acc: 0.8868
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5925 - acc: 0.8890
2100/4800 [============>.................] - ETA: 1s - loss: 0.5938 - acc: 0.8906
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5935 - acc: 0.8911
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5933 - acc: 0.8922
3000/4800 [=================>............] - ETA: 0s - loss: 0.5927 - acc: 0.8940
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5931 - acc: 0.8920
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5933 - acc: 0.8932
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5934 - acc: 0.8917
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5930 - acc: 0.8935
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5930 - acc: 0.8939
4800/4800 [==============================] - 3s 547us/step - loss: 0.5929 - acc: 0.8957 - val_loss: 0.4038 - val_acc: 0.8970
Epoch 11/20

 300/4800 [>.............................] - ETA: 1s - loss: 0.5902 - acc: 0.9092
 600/4800 [==>...........................] - ETA: 1s - loss: 0.5916 - acc: 0.9013
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5930 - acc: 0.8961
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5918 - acc: 0.8977
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5943 - acc: 0.8900
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5939 - acc: 0.8892
2100/4800 [============>.................] - ETA: 1s - loss: 0.5932 - acc: 0.8913
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5928 - acc: 0.8919
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5920 - acc: 0.8941
3000/4800 [=================>............] - ETA: 0s - loss: 0.5927 - acc: 0.8940
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5929 - acc: 0.8941
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5928 - acc: 0.8933
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5927 - acc: 0.8917
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5925 - acc: 0.8932
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5927 - acc: 0.8937
4800/4800 [==============================] - 3s 544us/step - loss: 0.5926 - acc: 0.8957 - val_loss: 0.4116 - val_acc: 0.8970
Epoch 12/20

 300/4800 [>.............................] - ETA: 1s - loss: 0.5971 - acc: 0.8896
 600/4800 [==>...........................] - ETA: 1s - loss: 0.5950 - acc: 0.8850
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5937 - acc: 0.8879
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5939 - acc: 0.8860
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5937 - acc: 0.8894
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5925 - acc: 0.8908
2100/4800 [============>.................] - ETA: 1s - loss: 0.5922 - acc: 0.8936
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5920 - acc: 0.8926
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5922 - acc: 0.8945
3000/4800 [=================>............] - ETA: 0s - loss: 0.5926 - acc: 0.8959
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5928 - acc: 0.8970
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5925 - acc: 0.8971
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5921 - acc: 0.8965
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5919 - acc: 0.8970
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5918 - acc: 0.8965
4800/4800 [==============================] - 3s 537us/step - loss: 0.5920 - acc: 0.8957 - val_loss: 0.3783 - val_acc: 0.8970
Epoch 13/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5937 - acc: 0.8945
 600/4800 [==>...........................] - ETA: 1s - loss: 0.5967 - acc: 0.8774
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5944 - acc: 0.8835
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5949 - acc: 0.8880
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5940 - acc: 0.8909
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5934 - acc: 0.8913
2100/4800 [============>.................] - ETA: 1s - loss: 0.5936 - acc: 0.8921
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5932 - acc: 0.8934
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5916 - acc: 0.8961
3000/4800 [=================>............] - ETA: 0s - loss: 0.5916 - acc: 0.8971
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5917 - acc: 0.8961
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5915 - acc: 0.8967
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5917 - acc: 0.8962
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5915 - acc: 0.8970
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5914 - acc: 0.8958
4800/4800 [==============================] - 3s 542us/step - loss: 0.5912 - acc: 0.8957 - val_loss: 0.4154 - val_acc: 0.8970
Epoch 14/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5900 - acc: 0.9001
 600/4800 [==>...........................] - ETA: 2s - loss: 0.5852 - acc: 0.8932
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5854 - acc: 0.8939
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5892 - acc: 0.8892
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5912 - acc: 0.8900
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5906 - acc: 0.8944
2100/4800 [============>.................] - ETA: 1s - loss: 0.5893 - acc: 0.8953
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5893 - acc: 0.8959
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5899 - acc: 0.8943
3000/4800 [=================>............] - ETA: 0s - loss: 0.5903 - acc: 0.8924
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5906 - acc: 0.8928
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5913 - acc: 0.8935
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5910 - acc: 0.8945
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5906 - acc: 0.8965
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5909 - acc: 0.8963
4800/4800 [==============================] - 3s 553us/step - loss: 0.5911 - acc: 0.8957 - val_loss: 0.4139 - val_acc: 0.8971
Epoch 15/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5931 - acc: 0.8900
 600/4800 [==>...........................] - ETA: 2s - loss: 0.5948 - acc: 0.8977
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5954 - acc: 0.8998
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5955 - acc: 0.8982
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5948 - acc: 0.8963
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5965 - acc: 0.8967
2100/4800 [============>.................] - ETA: 1s - loss: 0.5958 - acc: 0.8971
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5950 - acc: 0.8978
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5941 - acc: 0.8990
3000/4800 [=================>............] - ETA: 0s - loss: 0.5942 - acc: 0.9003
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5941 - acc: 0.8991
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5935 - acc: 0.8972
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5937 - acc: 0.8971
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5932 - acc: 0.8966
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5929 - acc: 0.8964
4800/4800 [==============================] - 2s 518us/step - loss: 0.5931 - acc: 0.8957 - val_loss: 0.4032 - val_acc: 0.8970
Epoch 16/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5925 - acc: 0.9009
 600/4800 [==>...........................] - ETA: 2s - loss: 0.5947 - acc: 0.8912
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5941 - acc: 0.8951
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5926 - acc: 0.8955
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5932 - acc: 0.8957
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5932 - acc: 0.8976
2100/4800 [============>.................] - ETA: 1s - loss: 0.5925 - acc: 0.8956
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5923 - acc: 0.8980
2700/4800 [===============>..............] - ETA: 0s - loss: 0.5925 - acc: 0.8961
3000/4800 [=================>............] - ETA: 0s - loss: 0.5916 - acc: 0.8966
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5921 - acc: 0.8957
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5915 - acc: 0.8971
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5917 - acc: 0.8966
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5916 - acc: 0.8963
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5916 - acc: 0.8957
4800/4800 [==============================] - 2s 519us/step - loss: 0.5910 - acc: 0.8958 - val_loss: 0.4058 - val_acc: 0.8971
Epoch 17/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5867 - acc: 0.9029
 600/4800 [==>...........................] - ETA: 1s - loss: 0.5864 - acc: 0.8961
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5869 - acc: 0.8924
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5887 - acc: 0.8913
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5895 - acc: 0.8899
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5885 - acc: 0.8926
2100/4800 [============>.................] - ETA: 1s - loss: 0.5879 - acc: 0.8937
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5878 - acc: 0.8939
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5885 - acc: 0.8935
3000/4800 [=================>............] - ETA: 0s - loss: 0.5886 - acc: 0.8929
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5885 - acc: 0.8934
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5890 - acc: 0.8947
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5892 - acc: 0.8943
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5892 - acc: 0.8960
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5895 - acc: 0.8956
4800/4800 [==============================] - 3s 547us/step - loss: 0.5891 - acc: 0.8958 - val_loss: 0.3731 - val_acc: 0.8975
Epoch 18/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5887 - acc: 0.9044
 600/4800 [==>...........................] - ETA: 1s - loss: 0.5934 - acc: 0.8965
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5918 - acc: 0.9031
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5905 - acc: 0.9012
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5891 - acc: 0.9011
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5891 - acc: 0.9004
2100/4800 [============>.................] - ETA: 1s - loss: 0.5901 - acc: 0.8971
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5898 - acc: 0.8974
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5895 - acc: 0.8975
3000/4800 [=================>............] - ETA: 0s - loss: 0.5900 - acc: 0.8965
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5895 - acc: 0.8960
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5898 - acc: 0.8951
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5897 - acc: 0.8948
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5894 - acc: 0.8947
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5889 - acc: 0.8951
4800/4800 [==============================] - 3s 545us/step - loss: 0.5887 - acc: 0.8959 - val_loss: 0.4000 - val_acc: 0.8981
Epoch 19/20

 300/4800 [>.............................] - ETA: 1s - loss: 0.5934 - acc: 0.8891
 600/4800 [==>...........................] - ETA: 1s - loss: 0.5902 - acc: 0.9037
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5885 - acc: 0.9016
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5911 - acc: 0.8967
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5908 - acc: 0.8981
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5900 - acc: 0.8964
2100/4800 [============>.................] - ETA: 1s - loss: 0.5895 - acc: 0.8957
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5882 - acc: 0.8977
2700/4800 [===============>..............] - ETA: 1s - loss: 0.5888 - acc: 0.8960
3000/4800 [=================>............] - ETA: 0s - loss: 0.5884 - acc: 0.8976
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5879 - acc: 0.8967
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5877 - acc: 0.8981
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5871 - acc: 0.8995
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5872 - acc: 0.8999
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5869 - acc: 0.9016
4800/4800 [==============================] - 3s 543us/step - loss: 0.5875 - acc: 0.9010 - val_loss: 0.3869 - val_acc: 0.9431
Epoch 20/20

 300/4800 [>.............................] - ETA: 2s - loss: 0.5903 - acc: 0.9025
 600/4800 [==>...........................] - ETA: 1s - loss: 0.5921 - acc: 0.9103
 900/4800 [====>.........................] - ETA: 1s - loss: 0.5917 - acc: 0.9116
1200/4800 [======>.......................] - ETA: 1s - loss: 0.5895 - acc: 0.9118
1500/4800 [========>.....................] - ETA: 1s - loss: 0.5889 - acc: 0.9127
1800/4800 [==========>...................] - ETA: 1s - loss: 0.5870 - acc: 0.9111
2100/4800 [============>.................] - ETA: 1s - loss: 0.5864 - acc: 0.9119
2400/4800 [==============>...............] - ETA: 1s - loss: 0.5864 - acc: 0.9113
2700/4800 [===============>..............] - ETA: 0s - loss: 0.5858 - acc: 0.9104
3000/4800 [=================>............] - ETA: 0s - loss: 0.5854 - acc: 0.9078
3300/4800 [===================>..........] - ETA: 0s - loss: 0.5850 - acc: 0.9093
3600/4800 [=====================>........] - ETA: 0s - loss: 0.5847 - acc: 0.9112
3900/4800 [=======================>......] - ETA: 0s - loss: 0.5850 - acc: 0.9103
4200/4800 [=========================>....] - ETA: 0s - loss: 0.5849 - acc: 0.9092
4500/4800 [===========================>..] - ETA: 0s - loss: 0.5851 - acc: 0.9087
4800/4800 [==============================] - 2s 519us/step - loss: 0.5847 - acc: 0.9085 - val_loss: 0.3835 - val_acc: 0.9451
C:\Anaconda3\lib\site-packages\h5py\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
Finished
